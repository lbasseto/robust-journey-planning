{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import calendar\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as functions\n",
    "import math\n",
    "import getpass\n",
    "import pyspark\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName('journey_planner-{0}'.format(getpass.getuser())) \\\n",
    "    .config('spark.jars.packages', 'graphframes:graphframes:0.6.0-spark2.3-s_2.11') \\\n",
    "    .config('spark.executor.memory', '8g') \\\n",
    "    .config('spark.executor.instances', '5') \\\n",
    "    .config('spark.port.maxRetries', '100') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate vertices and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = spark.read.csv('/datasets/sbb/2018/*/*istdaten.csv.bz2', sep=';', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations = pd.read_csv('data/filtered_stations.csv')\n",
    "valid_stations = set(stations['Remark'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vertices_df = stations[['Remark', 'Longitude', 'Latitude']]\n",
    "vertices_df.columns = ['id', 'lon', 'lat']\n",
    "vertices = spark.createDataFrame(vertices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations = stations[['Longitude', 'Latitude', 'Remark']];\n",
    "stations['key'] = 0\n",
    "\n",
    "earth_radius = 6371e3\n",
    "\n",
    "def haversine(row):\n",
    "    phi1         = 2 * math.pi * float(row['Latitude_x']) / 360\n",
    "    phi2         = 2 * math.pi * float(row['Latitude_y']) / 360\n",
    "    delta_phi    = 2 * math.pi * (float(row['Latitude_y']) - float(row['Latitude_x'])) / 360\n",
    "    delta_lambda = 2 * math.pi * (float(row['Longitude_y']) - float(row['Longitude_x'])) / 360\n",
    "    \n",
    "    a = (math.sin(delta_phi/2) ** 2) + \\\n",
    "        math.cos(phi1) * math.cos(phi2) * (math.sin(delta_lambda/2) ** 2)\n",
    "    \n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    \n",
    "    d = earth_radius * c\n",
    "    \n",
    "    return d / 1000\n",
    "\n",
    "prod = pd.merge(stations, stations, on='key')\n",
    "prod['dist'] = prod.apply(lambda row: haversine(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We don't consider walking to stops that are more than 3 kilometers away\n",
    "max_walking_distance = 3\n",
    "walk_df = prod[prod['dist'] <= max_walking_distance]\n",
    "walk_df = walk_df[walk_df['Remark_x'] != walk_df['Remark_y']]\n",
    "\n",
    "walk_df = walk_df[['Remark_x', 'Remark_y', 'dist']]\n",
    "walk_df['type'] = 'walk'\n",
    "walk_df['line'] = 'walk'\n",
    "walk_df['departure_day']  = 'null'\n",
    "walk_df['departure_time'] = 'null'\n",
    "walk_df['arrival_time']   = 'null'\n",
    "# We assume an average walking speed of 5 kilometers per hour\n",
    "walk_df['lateAvg'] = walk_df.apply(lambda row: 3600 * float(row['dist']) / 5, axis=1)\n",
    "walk_df['lateStd'] = 0.0\n",
    "walk_df.drop('dist', axis=1, inplace=True)\n",
    "walk_df.columns = ['src', 'dst', 'type', 'line', 'departure_day', 'departure_time', 'arrival_time', 'lateAvg', 'lateStd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "walk_edges = spark.createDataFrame(walk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transport edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateFormat = 'dd.MM.yyyy HH:mm'\n",
    "timeLate = (functions.unix_timestamp('AN_PROGNOSE', format=dateFormat)\n",
    "            - functions.unix_timestamp('ANKUNFTSZEIT', format=dateFormat))\n",
    "\n",
    "@functions.udf\n",
    "def clamp(late):\n",
    "    return 0 if late < 0 else late\n",
    "\n",
    "valid_stops = df.filter((df.DURCHFAHRT_TF=='false') & \n",
    "                        (df.FAELLT_AUS_TF=='false') & \n",
    "                        (df.ZUSATZFAHRT_TF=='false') &\n",
    "                        (df.AN_PROGNOSE_STATUS=='GESCHAETZT') &\n",
    "                        (df.HALTESTELLEN_NAME.isin(valid_stations))) \\\n",
    "                .select('BETRIEBSTAG',\n",
    "                        'FAHRT_BEZEICHNER', \n",
    "                        'PRODUKT_ID', \n",
    "                        'LINIEN_TEXT', \n",
    "                        'HALTESTELLEN_NAME', \n",
    "                        'AN_PROGNOSE',\n",
    "                        'ANKUNFTSZEIT', \n",
    "                        'ABFAHRTSZEIT') \\\n",
    "                .withColumn('AN_PROGNOSE',  functions.to_timestamp(df.AN_PROGNOSE, dateFormat))  \\\n",
    "                .withColumn('ANKUNFTSZEIT', functions.to_timestamp(df.ANKUNFTSZEIT, dateFormat)) \\\n",
    "                .withColumn('ABFAHRTSZEIT', functions.to_timestamp(df.ABFAHRTSZEIT, dateFormat)) \\\n",
    "                .withColumn('late', clamp(timeLate)) \\\n",
    "                .drop('AN_PROGNOSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "departures = valid_stops.filter(valid_stops.ABFAHRTSZEIT.isNotNull())\\\n",
    "                        .drop('ANKUNFTSZEIT', 'late')\n",
    "arrivals   = valid_stops.filter(valid_stops.ANKUNFTSZEIT.isNotNull())\\\n",
    "                        .drop('ABFAHRTSZEIT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrivals.createOrReplaceTempView('arrivals')\n",
    "departures.createOrReplaceTempView('departures')\n",
    "\n",
    "joinQuery = 'SELECT d.HALTESTELLEN_NAME AS src, a.HALTESTELLEN_NAME AS dst,              \\\n",
    "                    d.PRODUKT_ID AS type, d.LINIEN_TEXT AS line,                         \\\n",
    "                    date_format(d.ABFAHRTSZEIT, \\'EEEE\\') AS departure_day,              \\\n",
    "                    SUBSTRING(d.ABFAHRTSZEIT, 12, 8) AS departure_time,                  \\\n",
    "                    SUBSTRING(a.ANKUNFTSZEIT, 12, 8) AS arrival_time,                    \\\n",
    "                    a.late                                                               \\\n",
    "             FROM arrivals AS a INNER JOIN departures AS d                               \\\n",
    "             ON a.BETRIEBSTAG == d.BETRIEBSTAG                                           \\\n",
    "             AND a.FAHRT_BEZEICHNER == d.FAHRT_BEZEICHNER                                \\\n",
    "             WHERE a.HALTESTELLEN_NAME != d.HALTESTELLEN_NAME                            \\\n",
    "             AND d.ABFAHRTSZEIT < a.ANKUNFTSZEIT'\n",
    "\n",
    "edges = spark.sql(joinQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges.createOrReplaceTempView('edges')\n",
    "\n",
    "query = 'SELECT src, dst, type, line, departure_day, departure_time, arrival_time,              \\\n",
    "         AVG(late) AS lateAvg, STD(late) AS lateStd                                             \\\n",
    "         FROM edges GROUP BY src, dst, type, line, departure_day, departure_time, arrival_time'\n",
    "\n",
    "aggregated = spark.sql(query)\n",
    "aggregated_edges = aggregated.na.fill(0.0)\n",
    "\n",
    "all_edges = aggregated_edges.union(walk_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_edges.write.parquet('/homes/schmutz/edges', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vertices.write.parquet('/homes/schmutz/vertices', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load data from hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vertices = spark.read.parquet('/homes/schmutz/vertices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----------------+\n",
      "|                  id|              lon|              lat|\n",
      "+--------------------+-----------------+-----------------+\n",
      "|   Zumikon, Gössikon|         8.614773|        47.332474|\n",
      "|   Zumikon, Waltikon|         8.618188|        47.336109|\n",
      "|Zumikon, Dorfzentrum|         8.622922|        47.332976|\n",
      "|Zürich, Meierhofp...|         8.499375|        47.402009|\n",
      "|  Zürich, Heizenholz|8.483903999999999|47.41229600000001|\n",
      "+--------------------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vertices.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges = spark.read.parquet('/homes/schmutz/edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+----+-------------+--------------+------------+------------------+-------+\n",
      "|                 src|                 dst|type|line|departure_day|departure_time|arrival_time|           lateAvg|lateStd|\n",
      "+--------------------+--------------------+----+----+-------------+--------------+------------+------------------+-------+\n",
      "|Thalwil, Archstrasse|Thalwil, Feldstrasse|walk|walk|         null|          null|        null|472.61572587575955|    0.0|\n",
      "|Thalwil, Archstrasse|Thalwil, Mühlebac...|walk|walk|         null|          null|        null| 421.5532234300196|    0.0|\n",
      "|Thalwil, Archstrasse|    Thalwil, Zentrum|walk|walk|         null|          null|        null|175.33795811343845|    0.0|\n",
      "|Thalwil, Archstrasse|    Thalwil, Bahnhof|walk|walk|         null|          null|        null|184.83110825655203|    0.0|\n",
      "|Thalwil, Archstrasse|Küsnacht ZH, Ob. ...|walk|walk|         null|          null|        null| 2109.991732919267|    0.0|\n",
      "+--------------------+--------------------+----+----+-------------+--------------+------------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive Journey Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MINUTES_PER_DAY = 1440\n",
    "MINUTES_PER_HOUR = 60\n",
    "SECONDS_PER_MINUTE = 60\n",
    "\n",
    "def computeDiff(departure, arrival):\n",
    "    dep = (departure[2:]).split(':')\n",
    "    arr = (arrival[2:]).split(':')\n",
    "    a = (int(arrival[:1]) - int(departure[:1])) * MINUTES_PER_DAY\n",
    "    b = (int(arr[0]) - int(dep[0])) * MINUTES_PER_HOUR\n",
    "    c = (int(arr[1]) - int(dep[1]))\n",
    "    tot = a + b + c\n",
    "    hours = tot // MINUTES_PER_HOUR\n",
    "    minutes = tot % MINUTES_PER_HOUR\n",
    "    return \"{:02d}\".format(int(hours)) + ':' + \"{:02d}\".format(int(minutes)) + ':00'\n",
    "\n",
    "def computeCost(cost, late):\n",
    "    tmp = cost.split(':')\n",
    "    a = int(tmp[0][2:]) * MINUTES_PER_HOUR + int(tmp[1])\n",
    "    b = late // SECONDS_PER_MINUTE\n",
    "    prefix = tmp[0][:2] if a > b else '0-'\n",
    "    a = (a - b) % MINUTES_PER_DAY\n",
    "    minutes = a % MINUTES_PER_HOUR\n",
    "    hours = (a - minutes) // MINUTES_PER_HOUR\n",
    "    return prefix + \"{:02d}\".format(int(hours)) + ':' + \"{:02d}\".format(int(minutes)) + ':00'\n",
    "\n",
    "def getFilteredEdges(startDay, finishDay, startTime, finishTime, duration):\n",
    "    def valid(day, depTime, arrTime, walkTime):\n",
    "        if startDay==finishDay:\n",
    "            return ((day=='null') & (walkTime<=duration)) | \\\n",
    "                    ((day==startDay) & (depTime>=startTime) & (arrTime<=finishTime) & (depTime<=arrTime))\n",
    "        else:\n",
    "            return ((day=='null') & (walkTime<=duration)) | \\\n",
    "                    (((day==startDay) & (depTime>=startTime) & ((depTime<=arrTime) | (arrTime<=finishTime))) | \\\n",
    "                     ((day==finishDay) & (depTime<finishTime) & (arrTime<=finishTime)))\n",
    "\n",
    "    return graph.filterEdges(valid(graph.edges.departure_day, \n",
    "                                graph.edges.departure_time,\n",
    "                                graph.edges.arrival_time,\n",
    "                                graph.edges.lateAvg)).edges\n",
    "\n",
    "def add_vertice_to_set(max_set, vertice, vertice_costs, edges, next_vertices):\n",
    "    \n",
    "    max_set.add(vertice)\n",
    "    cost = vertice_costs[vertice]\n",
    "\n",
    "    vertice_edges = edges[((edges.dst == vertice) & (edges.type == 'walk')) \n",
    "                                  | ((edges.dst == vertice) \n",
    "                                  & (edges.arrival_time < cost))]\n",
    "\n",
    "    for i, edge in vertice_edges.iterrows():\n",
    "        if edge['type'] == 'walk':\n",
    "            new_cost = computeCost(cost, edge['lateAvg'])\n",
    "            if edge['src'] not in vertice_costs or new_cost > vertice_costs[edge.dst]:\n",
    "                next_vertices[edge['src']] = edge\n",
    "                vertice_costs[edge.src] = new_cost\n",
    "        elif edge['src'] not in vertice_costs or edge['departure_time'] > vertice_costs[edge['dst']]:\n",
    "            vertice_costs[edge['src']] = edge['departure_time']\n",
    "            next_vertices[edge['src']] = edge\n",
    "            \n",
    "\n",
    "def get_max_vertice_not_in_set(max_set, vertice_costs, min_trip_departure_time):\n",
    "    max_vertice = None\n",
    "    max_cost = min_trip_departure_time\n",
    "    for vertice in vertice_costs:\n",
    "        if vertice not in max_set and vertice_costs[vertice] > max_cost:\n",
    "            max_cost = vertice_costs[vertice]\n",
    "            max_vertice = vertice\n",
    "    \n",
    "    return max_vertice\n",
    "\n",
    "def find_path(next_vertices, current_vertice, current_path):\n",
    "    if current_vertice not in next_vertices:\n",
    "        return current_path\n",
    "    next_vertice = next_vertices[current_vertice]['dst']\n",
    "    current_path.append(next_vertices[current_vertice])\n",
    "    return find_path(next_vertices, next_vertice, current_path)\n",
    "    \n",
    "\n",
    "def find_shortest_path(departure_station, arrival_station, \n",
    "                       startDateTime, endDateTime, \n",
    "                       min_probability_of_sucess):\n",
    "    \n",
    "    print(startDateTime)\n",
    "    print(endDateTime)\n",
    "    \n",
    "    startTime  = str(startDateTime.time())\n",
    "    endTime = str(endDateTime.time())\n",
    "\n",
    "    startDay  = calendar.day_name[startDateTime.weekday()]\n",
    "    endDay = calendar.day_name[endDateTime.weekday()]\n",
    "    \n",
    "    min_trip_departure_time = '0-' + startTime\n",
    "    \n",
    "    endTimePrefix = '0-' if (startDay == endDay) else '1-'\n",
    "    requested_arrival_time = endTimePrefix + endTime\n",
    "    \n",
    "    duration = (endDateTime - startDateTime).seconds\n",
    "    \n",
    "    print(startDay, startTime)\n",
    "    print(endDay, endTime)\n",
    "    \n",
    "    filtered_edges = getFilteredEdges(startDay, endDay, startTime, endTime, duration).toPandas()\n",
    "    \n",
    "    def to_dt(time):\n",
    "        if time == 'null':\n",
    "            return 'null'\n",
    "        elif time >= startTime:\n",
    "            return '0-' + time\n",
    "        else:\n",
    "            return '1-' + time\n",
    "    \n",
    "    filtered_edges['departure_time'] = filtered_edges['departure_time'].map(lambda x: to_dt(x))\n",
    "    filtered_edges['arrival_time']   = filtered_edges['arrival_time'].map(lambda x: to_dt(x))\n",
    "    \n",
    "    # as day#-hh-mm-ss\n",
    "    vertice_costs = {}\n",
    "    vertice_costs[arrival_station] = requested_arrival_time\n",
    "\n",
    "    max_set = set()\n",
    "    next_vertices = {}\n",
    "    add_vertice_to_set(max_set, arrival_station, vertice_costs, filtered_edges, next_vertices)\n",
    "    no_solution = False\n",
    "    while(departure_station not in max_set and not no_solution):\n",
    "        max_vertice = get_max_vertice_not_in_set(max_set, vertice_costs, min_trip_departure_time)\n",
    "        if max_vertice is None:\n",
    "            no_solution = True\n",
    "        else:\n",
    "            add_vertice_to_set(max_set, max_vertice, vertice_costs, filtered_edges, next_vertices)\n",
    "    \n",
    "    if no_solution:\n",
    "        print(\"no solution\", vertice_costs)\n",
    "    \n",
    "    departure_time = (vertice_costs[departure_station])[2:]\n",
    "        \n",
    "    trip_duration = computeDiff(vertice_costs[departure_station], requested_arrival_time)\n",
    "    \n",
    "    return departure_time, trip_duration, find_path(next_vertices, departure_station, [departure_station])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-03 18:16:00\n",
      "2019-06-03 20:57:00\n",
      "Monday 18:16:00\n",
      "Monday 20:57:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('19:39:00', '01:18:00', ['Kilchberg', src                 Kilchberg\n",
       "  dst               Wallisellen\n",
       "  type                      Zug\n",
       "  line                       S8\n",
       "  departure_day          Monday\n",
       "  departure_time     0-19:39:00\n",
       "  arrival_time       0-20:03:00\n",
       "  lateAvg                    20\n",
       "  lateStd               29.1043\n",
       "  Name: 119636, dtype: object, src               Wallisellen\n",
       "  dst                    Urdorf\n",
       "  type                      Zug\n",
       "  line                      S14\n",
       "  departure_day          Monday\n",
       "  departure_time     0-20:07:00\n",
       "  arrival_time       0-20:29:00\n",
       "  lateAvg                     0\n",
       "  lateStd                     0\n",
       "  Name: 119546, dtype: object, src                                 Urdorf\n",
       "  dst               Urdorf, Schlierenstrasse\n",
       "  type                                  walk\n",
       "  line                                  walk\n",
       "  departure_day                         null\n",
       "  departure_time                        null\n",
       "  arrival_time                          null\n",
       "  lateAvg                            626.844\n",
       "  lateStd                                  0\n",
       "  Name: 49320, dtype: object])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fromStation = 'Kilchberg'\n",
    "toStation   = 'Urdorf, Schlierenstrasse'\n",
    "startDateTime = datetime(2019, 6, 3, 18, 16)\n",
    "endDateTime   = datetime(2019, 6, 3, 20, 57)\n",
    "\n",
    "res = find_shortest_path(fromStation, toStation, \n",
    "                   startDateTime, \n",
    "                   endDateTime, 0)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCHIVED CODE FOR POSSIBLE REUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSubGraph(graph, startDay, finishDay, startTime, finishTime, duration):\n",
    "    def valid(day, depTime, arrTime, walkTime):\n",
    "        if startDay==finishDay:\n",
    "            return ((day=='null') & (walkTime<=duration)) | \\\n",
    "                    ((day==startDay) & (depTime>=startTime) & (arrTime<=finishTime) & (depTime<=arrTime))\n",
    "        else:\n",
    "            return ((day=='null') & (walkTime<=duration)) | \\\n",
    "                    (((day==startDay) & (depTime>=startTime) & ((depTime<=arrTime) | (arrTime<=finishTime))) | \\\n",
    "                     ((day==finishDay) & (depTime<finishTime) & (arrTime<=finishTime)))\n",
    "\n",
    "    return graph.filterEdges(valid(graph.edges.departure_day, \n",
    "                                graph.edges.departure_time,\n",
    "                                graph.edges.arrival_time,\n",
    "                                graph.edges.lateAvg))  \\\n",
    "                .dropIsolatedVertices()\n",
    "\n",
    "def howFarNaive(graph, fromStation, startDateTime, duration):\n",
    "    \n",
    "    if duration >= 120:\n",
    "        print('You can walk anywhere in that time')\n",
    "        return\n",
    "    \n",
    "    finishDateTime = startDateTime + timedelta(minutes=duration)\n",
    "\n",
    "    startTime  = str(startDateTime.time())\n",
    "    finishTime = str(finishDateTime.time())\n",
    "\n",
    "    startDay  = calendar.day_name[startDateTime.weekday()]\n",
    "    finishDay = calendar.day_name[finishDateTime.weekday()]\n",
    "\n",
    "    print(startDay, startTime)\n",
    "    print(finishDay, finishTime)\n",
    "    \n",
    "    @functions.udf\n",
    "    def addTime(arr_time, dep_time, late):\n",
    "        if arr_time=='null':\n",
    "            tmp = dep_time.split(':')\n",
    "            return str((datetime.combine(date.today(), dt.time(int(tmp[0]), int(tmp[1]), int(tmp[2]))) + \n",
    "                        timedelta(seconds=int(late))).time())\n",
    "        else:\n",
    "            return arr_time\n",
    "    \n",
    "    @functions.udf\n",
    "    def checkDay(day, dep_time, arr_time):\n",
    "        return finishDay if arr_time<dep_time else day\n",
    "    \n",
    "    @functions.udf\n",
    "    def checkWalk(ttype):\n",
    "        return 1 if ttype=='walk' else 0\n",
    "    \n",
    "    @functions.udf\n",
    "    def checkIfValid(arr_time, day):\n",
    "        tmp = arr_time.split(':')\n",
    "        arr_date = startDateTime.date() if day==calendar.day_name[startDateTime.weekday()] else finishDateTime.date()\n",
    "        arrival = datetime.combine(arr_date, dt.time(int(tmp[0]), int(tmp[1]), int(tmp[2])))\n",
    "        return arrival < finishDateTime\n",
    "    \n",
    "    reachable = vertices.filter(vertices.id==fromStation)             \\\n",
    "                        .withColumn('time', functions.lit(startTime)) \\\n",
    "                        .withColumn('day', functions.lit(startDay))   \\\n",
    "                        .withColumn('just_walked', functions.lit(0))\n",
    "    \n",
    "    g = getSubGraph(graph, startDay, finishDay, startTime, finishTime, 60*duration)\n",
    "    g.persist();\n",
    "    g.edges.createOrReplaceTempView('edges')\n",
    "    g.vertices.createOrReplaceTempView('vertices')\n",
    "    \n",
    "    curr = reachable\n",
    "    \n",
    "    #while len(curr.head(1)) > 0:\n",
    "    for i in range(1):\n",
    "        curr.createOrReplaceTempView('curr')\n",
    "\n",
    "        query = 'SELECT v.*, c.time AS past_time, c.just_walked, c.day, e.type,          \\\n",
    "                        e.departure_time, e.arrival_time, e.lateAvg                      \\\n",
    "                 FROM curr AS c INNER JOIN edges AS e INNER JOIN vertices AS v           \\\n",
    "                 ON c.id==e.src                                                          \\\n",
    "                 AND e.dst==v.id                                                         \\\n",
    "                 WHERE (e.type!=\\'walk\\' OR c.just_walked==0)                            \\\n",
    "                 AND (e.type==\\'walk\\'                                                   \\\n",
    "                 OR (e.departure_time>=c.time AND c.day==e.departure_day)                \\\n",
    "                 OR (e.departure_time<c.time AND c.day!=e.departure_day))'\n",
    "\n",
    "        curr = spark.sql(query).withColumn('time', addTime('arrival_time', 'past_time', 'lateAvg')) \\\n",
    "                               .withColumn('day', checkDay('day', 'past_time', 'time'))             \\\n",
    "                               .filter(checkIfValid('time', 'day')=='true')                         \\\n",
    "                               .withColumn('just_walked', checkWalk('type'))                        \\\n",
    "                               .select('id', 'lon', 'lat', 'time', 'day', 'just_walked')\n",
    "        curr.persist()\n",
    "        reachable = reachable.union(curr)\n",
    "    \n",
    "    @functions.udf\n",
    "    def computeRadius(arr_time, day):\n",
    "        tmp = arr_time.split(':')\n",
    "        arr_date = startDateTime.date() if day==calendar.day_name[startDateTime.weekday()] else finishDateTime.date()\n",
    "        arrival = datetime.combine(arr_date, dt.time(int(tmp[0]), int(tmp[1]), int(tmp[2])))\n",
    "        return (finishDateTime - arrival).seconds * 5 // 3.6\n",
    "    \n",
    "    reachable = reachable.withColumn('radius', computeRadius('time', 'day')) \\\n",
    "                         .select('id', 'lon', 'lat', 'radius', 'time', 'just_walked')                     \\\n",
    "                         .toPandas()\n",
    "    \n",
    "    g.unpersist();\n",
    "    \n",
    "    return reachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = GraphFrame(vertices, edges)\n",
    "fromStation = 'Dietlikon'\n",
    "startDateTime  = datetime(2019, 5, 31, 23, 45)\n",
    "duration = 60\n",
    "\n",
    "start = time.time()\n",
    "reachable = howFarNaive(graph, fromStation, startDateTime, duration)\n",
    "print(time.time() - start)\n",
    "reachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
