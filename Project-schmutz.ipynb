{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import calendar\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "import pyspark.sql.functions as functions\n",
    "import math\n",
    "import getpass\n",
    "import pyspark\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "import networkx as nx\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName('journey_planner-{0}'.format(getpass.getuser())) \\\n",
    "    .config('spark.jars.packages', 'graphframes:graphframes:0.6.0-spark2.3-s_2.11') \\\n",
    "    .config('spark.executor.memory', '8g') \\\n",
    "    .config('spark.executor.instances', '5') \\\n",
    "    .config('spark.port.maxRetries', '100') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate vertices and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = spark.read.csv('/datasets/sbb/2018/*/*istdaten.csv.bz2', sep=';', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('data/filtered_stations.csv')\n",
    "valid_stations = set(stations['Remark'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_df = stations[['Remark', 'Longitude', 'Latitude']]\n",
    "vertices_df.columns = ['id', 'lon', 'lat']\n",
    "vertices = spark.createDataFrame(vertices_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = stations[['Longitude', 'Latitude', 'Remark']];\n",
    "stations['key'] = 0\n",
    "\n",
    "earth_radius = 6371e3\n",
    "\n",
    "def haversine(row):\n",
    "    phi1         = 2 * math.pi * float(row['Latitude_x']) / 360\n",
    "    phi2         = 2 * math.pi * float(row['Latitude_y']) / 360\n",
    "    delta_phi    = 2 * math.pi * (float(row['Latitude_y']) - float(row['Latitude_x'])) / 360\n",
    "    delta_lambda = 2 * math.pi * (float(row['Longitude_y']) - float(row['Longitude_x'])) / 360\n",
    "    \n",
    "    a = (math.sin(delta_phi/2) ** 2) + \\\n",
    "        math.cos(phi1) * math.cos(phi2) * (math.sin(delta_lambda/2) ** 2)\n",
    "    \n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    \n",
    "    d = earth_radius * c\n",
    "    \n",
    "    return d / 1000\n",
    "\n",
    "prod = pd.merge(stations, stations, on='key')\n",
    "prod['dist'] = prod.apply(lambda row: haversine(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We don't consider walking to stops that are more than 1 kilometers away\n",
    "max_walking_distance = 1\n",
    "walk_df = prod[prod['dist'] <= max_walking_distance]\n",
    "walk_df = walk_df[walk_df['Remark_x'] != walk_df['Remark_y']]\n",
    "\n",
    "walk_df = walk_df[['Remark_x', 'Remark_y', 'dist']]\n",
    "walk_df['type'] = 'walk'\n",
    "walk_df['line'] = 'walk'\n",
    "walk_df['departure_day']  = 'null'\n",
    "walk_df['departure_time'] = 'null'\n",
    "walk_df['arrival_time']   = 'null'\n",
    "# We assume an average walking speed of 5 kilometers per hour\n",
    "# We also round the walking time to the upper minute\n",
    "walk_df['lateAvg'] = walk_df.apply(lambda row: 60 + 60 * ((60 * float(row['dist'])) // 5), axis=1)\n",
    "walk_df['lateStd'] = 0.0\n",
    "walk_df.drop('dist', axis=1, inplace=True)\n",
    "walk_df.columns = ['src', 'dst', 'type', 'line', 'departure_day', 'departure_time', 'arrival_time', 'lateAvg', 'lateStd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_edges = spark.createDataFrame(walk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transport edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateFormat = 'dd.MM.yyyy HH:mm'\n",
    "timeLate = (functions.unix_timestamp('AN_PROGNOSE', format=dateFormat)\n",
    "            - functions.unix_timestamp('ANKUNFTSZEIT', format=dateFormat))\n",
    "\n",
    "@functions.udf\n",
    "def clamp(late):\n",
    "    return 0 if late < 0 else late\n",
    "\n",
    "arrivals    = df.filter((df.DURCHFAHRT_TF=='false') & \n",
    "                        (df.FAELLT_AUS_TF=='false') & \n",
    "                        (df.ZUSATZFAHRT_TF=='false') &\n",
    "                        (df.AN_PROGNOSE_STATUS=='GESCHAETZT') &\n",
    "                        (df.HALTESTELLEN_NAME.isin(valid_stations))) \\\n",
    "                .select('BETRIEBSTAG',\n",
    "                        'FAHRT_BEZEICHNER', \n",
    "                        'PRODUKT_ID', \n",
    "                        'LINIEN_TEXT', \n",
    "                        'HALTESTELLEN_NAME', \n",
    "                        'AN_PROGNOSE',\n",
    "                        'ANKUNFTSZEIT') \\\n",
    "                .withColumn('AN_PROGNOSE',  functions.to_timestamp(df.AN_PROGNOSE, dateFormat))  \\\n",
    "                .withColumn('ANKUNFTSZEIT', functions.to_timestamp(df.ANKUNFTSZEIT, dateFormat)) \\\n",
    "                .withColumn('late', clamp(timeLate)) \\\n",
    "                .drop('AN_PROGNOSE')\n",
    "\n",
    "departures  = df.filter((df.DURCHFAHRT_TF=='false') & \n",
    "                        (df.FAELLT_AUS_TF=='false') & \n",
    "                        (df.ZUSATZFAHRT_TF=='false') &\n",
    "                        (df.ABFAHRTSZEIT.isNotNull()) &\n",
    "                        (df.HALTESTELLEN_NAME.isin(valid_stations))) \\\n",
    "                .select('BETRIEBSTAG',\n",
    "                        'FAHRT_BEZEICHNER', \n",
    "                        'PRODUKT_ID', \n",
    "                        'LINIEN_TEXT', \n",
    "                        'HALTESTELLEN_NAME', \n",
    "                        'ABFAHRTSZEIT') \\\n",
    "                .withColumn('ABFAHRTSZEIT', functions.to_timestamp(df.ABFAHRTSZEIT, dateFormat)) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrivals.createOrReplaceTempView('arrivals')\n",
    "departures.createOrReplaceTempView('departures')\n",
    "\n",
    "joinQuery = 'SELECT d.HALTESTELLEN_NAME AS src, a.HALTESTELLEN_NAME AS dst,              \\\n",
    "                    d.PRODUKT_ID AS type, d.LINIEN_TEXT AS line,                         \\\n",
    "                    date_format(d.ABFAHRTSZEIT, \\'EEEE\\') AS departure_day,              \\\n",
    "                    SUBSTRING(d.ABFAHRTSZEIT, 12, 8) AS departure_time,                  \\\n",
    "                    SUBSTRING(a.ANKUNFTSZEIT, 12, 8) AS arrival_time,                    \\\n",
    "                    a.late                                                               \\\n",
    "             FROM arrivals AS a INNER JOIN departures AS d                               \\\n",
    "             ON a.BETRIEBSTAG == d.BETRIEBSTAG                                           \\\n",
    "             AND a.FAHRT_BEZEICHNER == d.FAHRT_BEZEICHNER                                \\\n",
    "             WHERE a.HALTESTELLEN_NAME != d.HALTESTELLEN_NAME                            \\\n",
    "             AND d.ABFAHRTSZEIT < a.ANKUNFTSZEIT'\n",
    "\n",
    "edges = spark.sql(joinQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges.createOrReplaceTempView('edges')\n",
    "\n",
    "query = 'SELECT src, dst, type, line, departure_day, departure_time, arrival_time,              \\\n",
    "         AVG(late) AS lateAvg, STD(late) AS lateStd                                             \\\n",
    "         FROM edges GROUP BY src, dst, type, line, departure_day, departure_time, arrival_time'\n",
    "\n",
    "aggregated = spark.sql(query)\n",
    "aggregated_edges = aggregated.na.fill(0.0)\n",
    "\n",
    "all_edges = aggregated_edges.union(walk_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#all_edges.write.parquet('/homes/schmutz/edges', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertices.write.parquet('/homes/schmutz/vertices', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journey Planner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = spark.read.parquet('/homes/schmutz/vertices')\n",
    "\n",
    "edges = spark.read.parquet('/homes/schmutz/edges')\n",
    "\n",
    "graph = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define some constants\n",
    "\"\"\"\n",
    "MINUTES_PER_DAY = 1440\n",
    "MINUTES_PER_HOUR = 60\n",
    "SECONDS_PER_MINUTE = 60\n",
    "\n",
    "WALK_SPEED = 1000 * 5 / 60 # meters per minute\n",
    "\n",
    "\n",
    "def compute_length_in_minutes_between(departure, arrival):\n",
    "    \"\"\"\n",
    "    Computes the interval in minutes between the departure and arrival time\n",
    "    \"\"\"\n",
    "    \n",
    "    dep = (departure[2:]).split(':')\n",
    "    arr = (arrival[2:]).split(':')\n",
    "    day_minutes = (int(arrival[:1]) - int(departure[:1])) * MINUTES_PER_DAY\n",
    "    hour_minutes = (int(arr[0]) - int(dep[0])) * MINUTES_PER_HOUR\n",
    "    minutes = (int(arr[1]) - int(dep[1]))\n",
    "    return day_minutes + hour_minutes + minutes\n",
    "\n",
    "\n",
    "def compute_prob(arrival, late_avg, late_std, departure):\n",
    "    \"\"\"\n",
    "    Computes the probability that we can use the departure time given that we arrive at the \n",
    "    arrival time with a delay represented by a gaussian distribution with mean late_avg and \n",
    "    standard deviation late_std\n",
    "    \"\"\"\n",
    "    \n",
    "    length = compute_length_in_minutes_between(arrival, departure) * SECONDS_PER_MINUTE\n",
    "    if late_std != 0.0:\n",
    "        return stat.norm(loc=late_avg, scale=late_std).cdf(length)\n",
    "    elif late_avg <= length:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def compute_time_between(departure, arrival):\n",
    "    \"\"\"\n",
    "    Computes the interval in hh:mm:ss between the departure and arrival time\n",
    "    \"\"\"\n",
    "    \n",
    "    dep = (departure[2:]).split(':')\n",
    "    arr = (arrival[2:]).split(':')\n",
    "    a = (int(arrival[:1]) - int(departure[:1])) * MINUTES_PER_DAY\n",
    "    b = (int(arr[0]) - int(dep[0])) * MINUTES_PER_HOUR\n",
    "    c = (int(arr[1]) - int(dep[1]))\n",
    "    tot = a + b + c\n",
    "    hours = tot // MINUTES_PER_HOUR\n",
    "    minutes = tot % MINUTES_PER_HOUR\n",
    "    return \"{:02d}\".format(int(hours)) + ':' + \"{:02d}\".format(int(minutes)) + ':00'\n",
    "\n",
    "\n",
    "def time_op(start_time, duration, op='add'):\n",
    "    \"\"\"\n",
    "    Add or subtract the given duration to or from start_time\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp = start_time.split(':')\n",
    "    a = int(tmp[0][2:]) * MINUTES_PER_HOUR + int(tmp[1])\n",
    "    b = duration // SECONDS_PER_MINUTE\n",
    "    if op == 'add':\n",
    "        prefix = tmp[0][:2] if a + b < MINUTES_PER_DAY else '1-'\n",
    "        a = (a + b) % MINUTES_PER_DAY\n",
    "    elif op == 'sub':\n",
    "        prefix = tmp[0][:2] if a > b else '0-'\n",
    "        a = (a - b) % MINUTES_PER_DAY\n",
    "    minutes = a % MINUTES_PER_HOUR\n",
    "    hours = (a - minutes) // MINUTES_PER_HOUR\n",
    "    return prefix + \"{:02d}\".format(int(hours)) + ':' + \"{:02d}\".format(int(minutes)) + ':00'\n",
    "\n",
    "\n",
    "def add_time(start_time, duration):\n",
    "    \"\"\"\n",
    "    Add the given duration to start_time\n",
    "    \"\"\"\n",
    "    return time_op(start_time, duration, 'add')\n",
    "\n",
    "\n",
    "def sub_time(start_time, duration):\n",
    "    \"\"\"\n",
    "    Subtract the given duration from start_time\n",
    "    \"\"\"\n",
    "    return time_op(start_time, duration, 'sub')\n",
    "\n",
    "\n",
    "def get_filtered_edges(start_day, finish_day, start_time, finish_time, duration):\n",
    "    \"\"\"\n",
    "    Filters the GraphFrames graph of vertices and edges and returns only the edges that can be used \n",
    "    in a valid journey given the constraints\n",
    "    \"\"\"\n",
    "    \n",
    "    def valid(day, dep_time, arr_time, walk_time):\n",
    "        if start_day==finish_day:\n",
    "            return ((day=='null') & (walk_time<=duration)) | \\\n",
    "                    ((day==start_day) & (dep_time>=start_time) & (arr_time<=finish_time) & (dep_time<=arr_time))\n",
    "        else:\n",
    "            return ((day=='null') & (walk_time<=duration)) | \\\n",
    "                    (((day==start_day) & (dep_time>=start_time) & ((dep_time<=arr_time) | (arr_time<=finish_time))) | \\\n",
    "                     ((day==finish_day) & (dep_time<finish_time) & (arr_time<=finish_time)))\n",
    "\n",
    "    return graph.filterEdges(valid(graph.edges.departure_day, \n",
    "                                graph.edges.departure_time,\n",
    "                                graph.edges.arrival_time,\n",
    "                                graph.edges.lateAvg)).edges\n",
    "\n",
    "\n",
    "def add_vertex_to_set(max_set, vertex, vertice_costs, subgraph, next_vertices, certain_path, reverse):\n",
    "    \n",
    "    max_set.add(vertex)\n",
    "    cost = vertice_costs[vertex]\n",
    "    \n",
    "    if reverse:\n",
    "        vertice_edges = subgraph.out_edges(vertex, data=True)\n",
    "\n",
    "        for parallel_paths in vertice_edges:\n",
    "            edge = parallel_paths[2]\n",
    "            if edge['type'] == 'walk':\n",
    "                new_cost = add_time(cost, edge['lateAvg'])\n",
    "                if (vertex not in next_vertices or next_vertices[vertex]['type'] != 'walk') and \\\n",
    "                    (edge['dst'] not in vertice_costs or new_cost < vertice_costs[edge['dst']]):\n",
    "                    next_vertices[edge['dst']] = edge\n",
    "                    vertice_costs[edge['dst']] = new_cost\n",
    "            elif edge['departure_time'] > cost and \\\n",
    "                (edge['dst'] not in vertice_costs or edge['arrival_time'] < vertice_costs[edge['dst']]):\n",
    "                if (not certain_path) or vertex not in next_vertices or \\\n",
    "                    compute_prob(cost,  next_vertices[vertex]['lateAvg'], \n",
    "                                next_vertices[vertex]['lateStd'], edge['departure_time']) == 1:\n",
    "                    vertice_costs[edge['dst']] = edge['arrival_time']\n",
    "                    next_vertices[edge['dst']] = edge\n",
    "    else:\n",
    "        vertice_edges = subgraph.in_edges(vertex, data=True)\n",
    "\n",
    "        for parallel_paths in vertice_edges:\n",
    "            edge = parallel_paths[2]\n",
    "            if edge['type'] == 'walk':\n",
    "                new_cost = sub_time(cost, edge['lateAvg'])\n",
    "                if (vertex not in next_vertices or next_vertices[vertex]['type'] != 'walk') and \\\n",
    "                    (edge['src'] not in vertice_costs or new_cost > vertice_costs[edge['src']]):\n",
    "                    next_vertices[edge['src']] = edge\n",
    "                    vertice_costs[edge['src']] = new_cost\n",
    "            elif edge['arrival_time'] < cost and \\\n",
    "                (edge['src'] not in vertice_costs or edge['departure_time'] > vertice_costs[edge['src']]):\n",
    "                if (not certain_path) or compute_prob(edge['arrival_time'],  edge['lateAvg'], edge['lateStd'], cost) == 1:\n",
    "                    vertice_costs[edge['src']] = edge['departure_time']\n",
    "                    next_vertices[edge['src']] = edge\n",
    "\n",
    "                    \n",
    "def get_max_vertex_not_in_set(max_set, vertice_costs, min_trip_departure_time):\n",
    "    max_vertex = None\n",
    "    max_cost = min_trip_departure_time\n",
    "    for vertex in vertice_costs:\n",
    "        if vertex not in max_set and vertice_costs[vertex] > max_cost:\n",
    "            max_cost = vertice_costs[vertex]\n",
    "            max_vertex = vertex\n",
    "    \n",
    "    return max_vertex\n",
    "\n",
    "\n",
    "def get_min_vertex_not_in_set(max_set, vertice_costs, max_trip_arrival_time):\n",
    "    max_vertex = None\n",
    "    max_cost = max_trip_arrival_time\n",
    "    for vertex in vertice_costs:\n",
    "        if vertex not in max_set and vertice_costs[vertex] < max_cost:\n",
    "            max_cost = vertice_costs[vertex]\n",
    "            max_vertex = vertex\n",
    "    \n",
    "    return max_vertex\n",
    "\n",
    "\n",
    "def find_path(next_vertices, current_vertex, current_path, direction):\n",
    "    \"\"\"\n",
    "    Function only used for testing of find_shortest_path\n",
    "    find_path(next_vertices, target, [target], direction) returns between the departure and arrival station\n",
    "    the path is returned in reverse order if direction is set to src\n",
    "    \"\"\"\n",
    "    \n",
    "    if current_vertex not in next_vertices:\n",
    "        return current_path\n",
    "    next_vertex = next_vertices[current_vertex][direction]\n",
    "    current_path.append(next_vertices[current_vertex])\n",
    "    return find_path(next_vertices, next_vertex, current_path, direction)\n",
    "    \n",
    "\n",
    "def find_shortest_path(subgraph, departure_station, arrival_station, \n",
    "                       min_trip_departure_time, max_trip_arrival_time, duration, \n",
    "                       get_all_destinations=False, certain_path=False, reverse=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Uses Dijkstra's algorithm to find the shortest path between the departure station and the arrival station.\n",
    "    The functions expects a subgraph of all valid edges in the context of the query.\n",
    "    \n",
    "    Returns the latest possible departure time in order to arrive to the destination in time.\n",
    "    If get_all_destinations is set to True, it instead returns a dictionary mapping station names to latest possible \n",
    "    departure times at that station in order to arrive to the destination in time.\n",
    "    If certain_path is set to True, returns the latest possible departure time in order to arrive to the destination \n",
    "    in time and with 100% probability.\n",
    "    \n",
    "    If reverse is set to True, then the algorithm is run in reverse order:\n",
    "    Returns the earliest possible arrival time when leaving on or after the departure time.\n",
    "    If get_all_destinations is set to True, it instead returns a dictionary mapping station names to earliest possible \n",
    "    arrival times at that station if we left on of after the departure time.\n",
    "    If certain_path is set to True, returns the earliest possible arrival time when leaving on or after the departure \n",
    "    time and with 100% probability.\n",
    "    \"\"\"\n",
    "    \n",
    "    # as day#-hh-mm-ss\n",
    "    vertice_costs = {}\n",
    "    max_set = set()\n",
    "    next_vertices = {}\n",
    "    if reverse:\n",
    "        vertice_costs[departure_station] = min_trip_departure_time\n",
    "        target = arrival_station\n",
    "        add_vertex_to_set(max_set, departure_station, vertice_costs, subgraph, next_vertices, certain_path, reverse)\n",
    "        direction = 'src'\n",
    "    else:\n",
    "        vertice_costs[arrival_station] = max_trip_arrival_time\n",
    "        target = departure_station\n",
    "        add_vertex_to_set(max_set, arrival_station, vertice_costs, subgraph, next_vertices, certain_path, reverse)\n",
    "        direction= 'dst'\n",
    "\n",
    "    no_solution = False\n",
    "    \n",
    "    while((target not in max_set or get_all_destinations) and not no_solution):\n",
    "        if reverse:\n",
    "            min_vertex = get_min_vertex_not_in_set(max_set, vertice_costs, max_trip_arrival_time)\n",
    "            if min_vertex is None:\n",
    "                no_solution = True\n",
    "            else:\n",
    "                add_vertex_to_set(max_set, min_vertex, vertice_costs, subgraph, next_vertices, certain_path, reverse)\n",
    "        else:\n",
    "            max_vertex = get_max_vertex_not_in_set(max_set, vertice_costs, min_trip_departure_time)\n",
    "            if max_vertex is None:\n",
    "                no_solution = True\n",
    "            else:\n",
    "                add_vertex_to_set(max_set, max_vertex, vertice_costs, subgraph, next_vertices, certain_path, reverse)\n",
    "    \n",
    "    if get_all_destinations:\n",
    "        return vertice_costs\n",
    "    if no_solution:\n",
    "        return 'no solution'\n",
    "    \n",
    "    if reverse:\n",
    "        return vertice_costs[arrival_station]\n",
    "    else:\n",
    "        return vertice_costs[departure_station]\n",
    "\n",
    "\n",
    "def compute_expected_arrival_time(arr_time, late_avg, late_std, curr_prob, min_prob_success):\n",
    "    \"\"\"\n",
    "    Computes the upper bound of the arrival time meeting the uncertainty requirement given:\n",
    "    arr_time the scheduled arrival time\n",
    "    late_avg the expected delay\n",
    "    late_std the standard deviation of the delay\n",
    "    curr_prob the probability of catching the transport that got us here\n",
    "    min_prob_success the constraint on the uncertainty requirement we have to respect\n",
    "    \"\"\"\n",
    "    \n",
    "    if late_std != 0:\n",
    "        remaining_prob = min_prob_success / curr_prob\n",
    "        expected_late = stat.norm(loc=late_avg, scale=late_std).ppf(remaining_prob)\n",
    "        if expected_late < 0:\n",
    "            return arr_time\n",
    "        elif expected_late == np.inf:\n",
    "            return None\n",
    "        else:\n",
    "            return add_time(arr_time, expected_late)\n",
    "    else:\n",
    "        return add_time(arr_time, late_avg)\n",
    "\n",
    "\n",
    "def compute_paths_heatmap(src, subgraph, visited, \n",
    "                          curr_prob, curr_time, curr_lateAvg, curr_lateStd, \n",
    "                          min_trip_departure_time, \n",
    "                          times, last_line_taken, time_limits, min_prob_success):\n",
    "    \"\"\"\n",
    "    Explore the paths to obtain the heatmap\n",
    "    src is the current location\n",
    "    subgraph is the set of valid edges\n",
    "    visited is a set of already visited stations in the current path\n",
    "    curr_prob is the current probability of reaching this location\n",
    "    curr_time is the time at which we arrived at this location according to the schedule\n",
    "    curr_lateAvg is the delay we expect to add to curr_time to arrive at this location\n",
    "    curr_lateStd is the standard deviation of the delay\n",
    "    min_trip_departure time is the time when we began moving from the first station\n",
    "    times is a dictionary of stations mapping to the earliest arrival time at that station (this function builds this map)\n",
    "    last_line_taken is the line we took coming from the previous station\n",
    "    time_limits is a dictionary mapping from stations to the earliest possible arrival time at that station with a probability \n",
    "    of 100%\n",
    "    min_pro_success is the constraint on the uncertainty requirement we have to respect\n",
    "    \"\"\"\n",
    "    \n",
    "    visited.add(src)\n",
    "    \n",
    "    arr_time = compute_expected_arrival_time(curr_time, curr_lateAvg, curr_lateStd, curr_prob, min_prob_success)\n",
    "    \n",
    "    if arr_time is not None and (src not in times or times[src] > arr_time):\n",
    "        times[src] = arr_time\n",
    "    \n",
    "    vertice_edges = subgraph.out_edges(src, data=True)\n",
    "    for vertice_edge in vertice_edges:\n",
    "        edge = vertice_edge[2]\n",
    "\n",
    "        if edge['dst'] not in visited and edge['line'] != last_line_taken:\n",
    "\n",
    "            if edge['type'] == 'walk':\n",
    "                new_time = add_time(curr_time, edge['lateAvg'])\n",
    "\n",
    "                if edge['dst'] in time_limits and new_time <= time_limits[edge['dst']]:\n",
    "\n",
    "                    compute_paths_heatmap(edge['dst'], subgraph, visited, \n",
    "                                               curr_prob, new_time, curr_lateAvg, curr_lateStd, \n",
    "                                               min_trip_departure_time, times, \n",
    "                                               edge['line'], time_limits, min_prob_success)\n",
    "\n",
    "            elif edge['departure_time'] > curr_time and edge['dst'] in time_limits and \\\n",
    "                 edge['arrival_time'] <= time_limits[edge['dst']]:\n",
    "\n",
    "                prob = compute_prob(curr_time, curr_lateAvg, curr_lateStd, edge['departure_time'])\n",
    "                new_prob = curr_prob * prob\n",
    "\n",
    "                if new_prob >= min_prob_success:\n",
    "                    compute_paths_heatmap(edge['dst'], subgraph, visited, \n",
    "                                               new_prob, edge['arrival_time'], edge['lateAvg'], edge['lateStd'],\n",
    "                                               min_trip_departure_time, times, \n",
    "                                               edge['line'], time_limits, min_prob_success)\n",
    "        \n",
    "    visited.remove(src)\n",
    "\n",
    "\n",
    "def compute_heatmap(subgraph, departure_station, arrival_station,\n",
    "                    min_trip_departure_time, max_trip_arrival_time, duration,\n",
    "                    min_probability_of_success):\n",
    "    \"\"\"\n",
    "    Compute a heatmap\n",
    "    subgraph is the set of valid edges in the context of the query\n",
    "    departure_station is the station we want to start the heatmap from\n",
    "    arrival_station is a dummy argument that we do not use\n",
    "    min_trip_departure_time is the time when we can start moving\n",
    "    max_trip_arrival_time is the time when we must stop moving\n",
    "    duration is the difference between the two times\n",
    "    min_probability of sucess\n",
    "    \"\"\"\n",
    "    \n",
    "    time_fastest = find_shortest_path(subgraph, departure_station, arrival_station, \n",
    "                              min_trip_departure_time, max_trip_arrival_time, duration, \n",
    "                              get_all_destinations=True, reverse=True, certain_path=False)\n",
    "\n",
    "    time_limits = find_shortest_path(subgraph, departure_station, arrival_station, \n",
    "                              min_trip_departure_time, max_trip_arrival_time, duration, \n",
    "                              get_all_destinations=True, reverse=True, certain_path=True)\n",
    "    \n",
    "    for k, v in time_fastest.items():\n",
    "        if k not in time_limits:\n",
    "            time_limits[k] = max_trip_arrival_time\n",
    "\n",
    "\n",
    "    visited = set()\n",
    "    times = {}\n",
    "    compute_paths_heatmap(departure_station, subgraph, visited, 1.0, min_trip_departure_time, 0.0, 0.0, \n",
    "                          min_trip_departure_time, times, '', time_limits, min_probability_of_success)\n",
    "    \n",
    "    heat = {}\n",
    "    for k, v in times.items():\n",
    "        if v < max_trip_arrival_time:\n",
    "            heat[k] = WALK_SPEED * compute_length_in_minutes_between(v, max_trip_arrival_time)\n",
    "\n",
    "    return heat\n",
    "\n",
    "\n",
    "def compute_dep_time(max_arr_time, curr_path, edge=None):\n",
    "    \"\"\"\n",
    "    curr_path follows this format: [src, edge, edge, edge, ...] with the edges in normal order\n",
    "    max_arr_time is only used when computing the departure time of a path with only one (walking) edge \n",
    "    if edge is not None then it means we intend to append edge to the end of curr_path\n",
    "    Returns the departure time\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(curr_path) == 1:\n",
    "        dep = max_arr_time if edge is None else edge['departure_time']\n",
    "    elif curr_path[1]['type'] == 'walk':\n",
    "        if edge is not None and len(curr_path) == 2:\n",
    "            dep = sub_time(edge['departure_time'], curr_path[1]['lateAvg'])\n",
    "        elif len(curr_path) > 2:\n",
    "            dep = sub_time(curr_path[2]['departure_time'], curr_path[1]['lateAvg'])\n",
    "        else:\n",
    "            dep = sub_time(max_arr_time, curr_path[1]['lateAvg'])\n",
    "    else:\n",
    "        dep = curr_path[1]['departure_time']\n",
    "    \n",
    "    return dep\n",
    "\n",
    "\n",
    "def compute_arr_time(min_dep_time, curr_path, edge=None):\n",
    "    \"\"\"\n",
    "    curr_path follows this format: [dst, edge, edge, edge, ...] with the edges in reverse order\n",
    "    min_dep_time is only used when computing the arrival time of a path with only one (walking) edge \n",
    "    if edge is not None then it means we intend to append edge to the end of curr_path\n",
    "    Returns the arrival time\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(curr_path) == 1:\n",
    "        arr = min_dep_time if edge is None else edge['arrival_time']\n",
    "    elif curr_path[1]['type'] == 'walk':\n",
    "        if edge is not None and len(curr_path) == 2:\n",
    "            arr = add_time(edge['arrival_time'], curr_path[1]['lateAvg'])\n",
    "        elif len(curr_path) > 2:\n",
    "            arr = add_time(curr_path[2]['arrival_time'], curr_path[1]['lateAvg'])\n",
    "        else:\n",
    "            arr = add_time(min_dep_time, curr_path[1]['lateAvg'])\n",
    "    else:\n",
    "        arr = curr_path[1]['arrival_time']\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "def compute_paths_arrival_mode(src, dst, subgraph, visited, curr_path, \n",
    "                               curr_prob, curr_time, curr_lateAvg, curr_lateStd, \n",
    "                               min_trip_departure_time, max_trip_arrival_time, \n",
    "                               paths, last_line_taken, time_limits, min_prob_success, best_times):\n",
    "    \"\"\"\n",
    "    Use the depth first search algorithm on the subgraph to find the potential trips that depart the latest \n",
    "    while still meeting the uncertainty requirement\n",
    "    src is the current location\n",
    "    dst is the destination\n",
    "    subgraph is the set of edges valid under the constraints of the query\n",
    "    visited is the set of already visited stations in the current path\n",
    "    curr_path is the current path\n",
    "    curr_prob is the probability that the current path is possible\n",
    "    curr_time is the time we arrived at the current location\n",
    "    curr_lateAvg is the expected delay on current_time\n",
    "    curr_lateStd is the standard deviation of the delay\n",
    "    min_trip_departure_time is the time when we can start moving from the first station\n",
    "    max_trip_arrival_time is the time when we must arrive at the destination at the latest\n",
    "    paths is the list of possible paths meeting the requirements that we build in this function\n",
    "    last_line_taken is the line we last took to arrive at the current location\n",
    "    time_limits is a dictionary mapping stations to latest possible departure time to arrive at the destination in time\n",
    "    min_prob_success is the uncertainty requirement we have to respect\n",
    "    best_times is a dictionary containing a single entry where we store the latest departure time for which we can find a path\n",
    "    that we currently know\n",
    "    \"\"\"\n",
    "    \n",
    "    visited.add(src)\n",
    "    \n",
    "    if src == dst:\n",
    "        final_prob = compute_prob(curr_time, curr_lateAvg, curr_lateStd, max_trip_arrival_time) * curr_prob\n",
    "        if final_prob >= min_prob_success:\n",
    "            final_path = curr_path.copy()\n",
    "            final_path.append(curr_time)\n",
    "            final_path.append(final_prob)\n",
    "            \n",
    "            dep = compute_dep_time(min_trip_departure_time, final_path[:-2], None)\n",
    "            if dep > best_times['dep']:\n",
    "                best_times['dep'] = dep\n",
    "            \n",
    "            paths.append(final_path)\n",
    "            \n",
    "    else:\n",
    "        vertice_edges = subgraph.out_edges(src, data=True)\n",
    "        for vertice_edge in vertice_edges:\n",
    "            edge = vertice_edge[2]\n",
    "            \n",
    "            if edge['dst'] not in visited and edge['line'] != last_line_taken:\n",
    "                \n",
    "                if edge['type'] == 'walk':\n",
    "                    new_time = add_time(curr_time, edge['lateAvg'])\n",
    "                    \n",
    "                    if new_time <= max_trip_arrival_time and \\\n",
    "                       edge['dst'] in time_limits and new_time <= time_limits[edge['dst']]:\n",
    "\n",
    "                        curr_path.append(edge)\n",
    "                        compute_paths_arrival_mode(edge['dst'], dst, subgraph, visited, curr_path, \n",
    "                                                   curr_prob, new_time, curr_lateAvg, curr_lateStd, \n",
    "                                                   min_trip_departure_time, max_trip_arrival_time, paths, \n",
    "                                                   edge['line'], time_limits, min_prob_success, best_times)\n",
    "                        curr_path.pop();\n",
    "                        \n",
    "                elif edge['departure_time'] > curr_time and edge['dst'] in time_limits and \\\n",
    "                     edge['arrival_time'] <= time_limits[edge['dst']]:\n",
    "                        \n",
    "                    dep = compute_dep_time(curr_time, curr_path, edge = edge)\n",
    "                    \n",
    "                    prob = compute_prob(curr_time, curr_lateAvg, curr_lateStd, edge['departure_time'])\n",
    "                    new_prob = curr_prob * prob\n",
    "                    \n",
    "                    if dep >= best_times['dep'] and new_prob >= min_prob_success:\n",
    "                        curr_path.append(edge)\n",
    "                        compute_paths_arrival_mode(edge['dst'], dst, subgraph, visited, curr_path, \n",
    "                                                   new_prob, edge['arrival_time'], edge['lateAvg'], edge['lateStd'],\n",
    "                                                   min_trip_departure_time, max_trip_arrival_time, paths, \n",
    "                                                   edge['line'], time_limits, min_prob_success, best_times)\n",
    "                        curr_path.pop();\n",
    "        \n",
    "    visited.remove(src)\n",
    "\n",
    "\n",
    "def compute_paths_departure_mode(src, dst, subgraph, visited, curr_path, \n",
    "                                 curr_prob, curr_time, \n",
    "                                 min_trip_departure_time, max_trip_arrival_time, \n",
    "                                 paths, last_line_taken, time_limits, min_prob_success, best_times):\n",
    "    \"\"\"\n",
    "    Use the depth first search algorithm on the subgraph to find the potential trips that arrive the earliest \n",
    "    while still meeting the uncertainty requirement. In this function we begin our search from the destination to the source.\n",
    "    src is the source (departure station)\n",
    "    dst is the current location\n",
    "    subgraph is the set of edges valid under the constraints of the query\n",
    "    visited is the set of already visited stations in the current path\n",
    "    curr_path is the current path\n",
    "    curr_prob is the probability that the current path is possible\n",
    "    curr_time is the time we depart from the current location\n",
    "    min_trip_departure_time is the time when we can start moving from the first station\n",
    "    max_trip_arrival_time is the time when we must arrive at the destination at the latest\n",
    "    paths is the list of possible paths meeting the requirements that we build in this function\n",
    "    last_line_taken is the line we last take to arrive at the next location from the current location\n",
    "    time_limits is a dictionary mapping stations to earliest possible arrival time in order to depart from the source \n",
    "    after the min departure time\n",
    "    min_prob_success is the uncertainty requirement we have to respect\n",
    "    best_times is a dictionary containing a single entry where we store the earliest arrival time for which we can find a path\n",
    "    that we currently know\n",
    "    \"\"\"\n",
    "    \n",
    "    visited.add(dst)\n",
    "    \n",
    "    if src == dst:\n",
    "        final_path = curr_path.copy()\n",
    "        final_path.append(curr_time)\n",
    "        final_path.append(curr_prob)\n",
    "\n",
    "        arr = compute_arr_time(max_trip_arrival_time, final_path[:-2], None)\n",
    "        if arr < best_times['arr']:\n",
    "            best_times['arr'] = arr\n",
    "        \n",
    "        paths.append(final_path)\n",
    "            \n",
    "    else:\n",
    "        vertice_edges = subgraph.in_edges(dst, data=True)\n",
    "        for vertice_edge in vertice_edges:\n",
    "            edge = vertice_edge[2]\n",
    "            \n",
    "            if edge['src'] not in visited and edge['line'] != last_line_taken:\n",
    "                \n",
    "                if edge['type'] == 'walk':\n",
    "                    new_time = sub_time(curr_time, edge['lateAvg'])\n",
    "                    \n",
    "                    if new_time >= min_trip_departure_time and \\\n",
    "                       edge['src'] in time_limits and new_time >= time_limits[edge['src']]:\n",
    "\n",
    "                        curr_path.append(edge)\n",
    "                        compute_paths_departure_mode(src, edge['src'], subgraph, visited, curr_path, \n",
    "                                                     curr_prob, new_time, \n",
    "                                                     min_trip_departure_time, max_trip_arrival_time, paths, \n",
    "                                                     edge['line'], time_limits, min_prob_success, best_times)\n",
    "                        curr_path.pop();\n",
    "                        \n",
    "                elif edge['arrival_time'] < curr_time and edge['src'] in time_limits and \\\n",
    "                     edge['departure_time'] >= time_limits[edge['src']]:\n",
    "                    \n",
    "                    arr = compute_arr_time(curr_time, curr_path, edge = edge)\n",
    "                    \n",
    "                    prob = compute_prob(edge['arrival_time'], edge['lateAvg'], edge['lateStd'], curr_time)\n",
    "                    new_prob = curr_prob * prob\n",
    "                    \n",
    "                    if arr <= best_times['arr'] and new_prob >= min_prob_success:\n",
    "                        curr_path.append(edge)\n",
    "                        compute_paths_departure_mode(src, edge['src'], subgraph, visited, curr_path, \n",
    "                                                     new_prob, edge['departure_time'],\n",
    "                                                     min_trip_departure_time, max_trip_arrival_time, paths, \n",
    "                                                     edge['line'], time_limits, min_prob_success, best_times)\n",
    "                        curr_path.pop();\n",
    "        \n",
    "    visited.remove(dst)\n",
    "\n",
    "\n",
    "def dfs(subgraph, departure_station, arrival_station, \n",
    "        min_trip_departure_time, max_trip_arrival_time, duration, \n",
    "        min_probability_of_success, mode):\n",
    "    \"\"\"\n",
    "    Use the depth first search algorithm to find the trip that departs / arrives the latest / earliest while \n",
    "    still meeting the uncertainty requirement of the query\n",
    "    subgraph is the set of edges valid under the query constraints\n",
    "    departure_station and arrival station are the source and destination\n",
    "    min_trip_departure_time is the time when we can start moving\n",
    "    max_trip_arrival_time is the time when we must have arrived at the latest\n",
    "    duration is the difference of the two times\n",
    "    min_probability_of_success is the uncertainty requirement we have to respect\n",
    "    mode is either 'departure' (arrive at the destination at the earliest possible moment)\n",
    "    or 'arrival' (depart from the source at the latest possible moment)\n",
    "    \"\"\"\n",
    "    \n",
    "    reverse = mode == 'departure'\n",
    "    \n",
    "    # Find the latest departures / earliest arrivals for each reachable station\n",
    "    time_limits = find_shortest_path(subgraph, departure_station, arrival_station, \n",
    "                                     min_trip_departure_time, max_trip_arrival_time, duration, \n",
    "                                     get_all_destinations=True, reverse=reverse)\n",
    "    \n",
    "    # Find the departure / arrival time of the fastest 100% successful trip\n",
    "    fastest_certain_path = find_shortest_path(subgraph, departure_station, arrival_station, \n",
    "                                              min_trip_departure_time, max_trip_arrival_time, duration, \n",
    "                                              get_all_destinations=False, certain_path=True, reverse=reverse)\n",
    "    \n",
    "    visited = set()\n",
    "    curr_time = min_trip_departure_time if mode =='arrival' else max_trip_arrival_time\n",
    "    curr_path = [departure_station] if mode == 'arrival' else [arrival_station]\n",
    "    paths = []\n",
    "    \n",
    "    if fastest_certain_path != \"no solution\":\n",
    "        best_times = {'dep': fastest_certain_path} if mode == 'arrival' else {'arr': fastest_certain_path}\n",
    "    else:\n",
    "        best_times = {'dep': min_trip_departure_time} if mode == 'arrival' else {'arr': max_trip_arrival_time}\n",
    "    \n",
    "    # Compute the paths\n",
    "    if mode == 'arrival':\n",
    "        compute_paths_arrival_mode(departure_station, arrival_station, subgraph, \n",
    "                                   visited, curr_path, 1.0, curr_time, 0.0, 0.0, min_trip_departure_time, \n",
    "                                   max_trip_arrival_time, paths, '', time_limits, \n",
    "                                   min_probability_of_success, best_times)\n",
    "    else:\n",
    "        compute_paths_departure_mode(departure_station, arrival_station, subgraph, \n",
    "                                     visited, curr_path, 1.0, curr_time, min_trip_departure_time, \n",
    "                                     max_trip_arrival_time, paths, '', time_limits, \n",
    "                                     min_probability_of_success, best_times)\n",
    "    \n",
    "    if not paths:\n",
    "        return {'departure time' : '', 'arrival_time' : '', \n",
    "                'duration' : '', 'path': []}\n",
    "    \n",
    "    # Compute the departure / arrival time and duration of the possible trips\n",
    "    if mode == 'arrival':\n",
    "        times = [compute_time_between(compute_dep_time(max_trip_arrival_time, path[:-2], None), path[-2]) for path in paths]\n",
    "        dep_times = [compute_dep_time(max_trip_arrival_time, path[:-2], None) for path in paths]\n",
    "    else:\n",
    "        times = [compute_time_between(path[-2], compute_arr_time(min_trip_departure_time, path[:-2], None)) for path in paths]\n",
    "        arr_times = [compute_arr_time(min_trip_departure_time, path[:-2], None) for path in paths]\n",
    "    \n",
    "    best_path_idx = np.argmax(dep_times) if mode == 'arrival' else np.argmin(arr_times)\n",
    "    best_path = paths[best_path_idx]\n",
    "    \n",
    "    path_edges = best_path[1:-2]\n",
    "    if mode == 'departure':\n",
    "        path_edges.reverse()\n",
    "    \n",
    "    # Compute the departure and arrival time for walk edges and remove unnecessary data\n",
    "    for idx, edge in enumerate(path_edges):\n",
    "        if edge['type'] == 'walk':\n",
    "            if idx == 0:\n",
    "                if len(path_edges) == 1:\n",
    "                    if mode == 'arrival':\n",
    "                        edge['arrival_time'] = max_trip_arrival_time\n",
    "                        edge['departure_time'] = sub_time(edge['arrival_time'], edge['lateAvg'])\n",
    "                    else:\n",
    "                        edge['departure_time'] = min_trip_departure_time\n",
    "                        edge['arrival_time'] = add_time(edge['departure_time'], edge['lateAvg'])\n",
    "                else:\n",
    "                    edge['arrival_time'] = path_edges[1]['departure_time']\n",
    "                    edge['departure_time'] = sub_time(edge['arrival_time'], edge['lateAvg'])\n",
    "            else:\n",
    "                edge['departure_time'] = path_edges[idx - 1]['arrival_time']\n",
    "                edge['arrival_time'] = add_time(edge['departure_time'], edge['lateAvg'])\n",
    "            \n",
    "            edge.pop('line');\n",
    "                \n",
    "        edge.pop('departure_day');\n",
    "        edge.pop('lateAvg');\n",
    "        edge.pop('lateStd');\n",
    "    \n",
    "    # Remove prefix from the departure / arrival time\n",
    "    for edge in path_edges:\n",
    "        edge['departure_time'] = edge['departure_time'][2:]\n",
    "        edge['arrival_time'] = edge['arrival_time'][2:]\n",
    "    \n",
    "    departure_time = path_edges[0]['departure_time']\n",
    "    arrival_time = path_edges[-1]['arrival_time']\n",
    "    \n",
    "    return {'departure_time' : departure_time, 'arrival_time' : arrival_time, \n",
    "            'duration' : times[best_path_idx], 'probability': best_path[-1], 'path': path_edges}\n",
    "\n",
    "\n",
    "def plan(departure_station, arrival_station=None, \n",
    "         start_datetime=None, end_datetime=None, \n",
    "         min_probability_of_success=0.0, \n",
    "         heatmap=False, heatmap_duration=10):\n",
    "    \"\"\"\n",
    "    Parses the query, creates the subgraph of valid edges in the context of the query, and calls the appropriate\n",
    "    function to compute the result.\n",
    "    \"\"\"\n",
    "\n",
    "    if min_probability_of_success < 0.0:\n",
    "        min_probability_of_success = 0.0\n",
    "    elif min_probability_of_success > 1.0:\n",
    "        min_probability_of_success = 1.0\n",
    "    \n",
    "    if heatmap:\n",
    "        if start_datetime is None:\n",
    "            return {}\n",
    "        else:\n",
    "            if heatmap_duration < 0:\n",
    "                heatmap_duration = 0\n",
    "            elif heatmap_duration > 120:\n",
    "                heatmap_duration = 120\n",
    "            end_datetime = start_datetime + timedelta(minutes=heatmap_duration)\n",
    "        \n",
    "    else:\n",
    "        if (start_datetime is None and end_datetime is None) or \\\n",
    "           (start_datetime is not None and end_datetime is not None) or \\\n",
    "            arrival_station is None:\n",
    "            return {'departure time' : '', 'arrival_time' : '', \n",
    "                    'duration' : '', 'path': []}\n",
    "\n",
    "        elif start_datetime is None:\n",
    "            mode = 'arrival'\n",
    "            start_datetime = end_datetime - timedelta(hours=2)\n",
    "\n",
    "        else:\n",
    "            mode = 'departure'\n",
    "            end_datetime = start_datetime + timedelta(hours=2)\n",
    "\n",
    "    start_time  = str(start_datetime.time())\n",
    "    end_time = str(end_datetime.time())\n",
    "\n",
    "    start_day  = calendar.day_name[start_datetime.weekday()]\n",
    "    end_day = calendar.day_name[end_datetime.weekday()]\n",
    "\n",
    "    min_trip_departure_time = '0-' + start_time\n",
    "\n",
    "    end_time_prefix = '0-' if (start_day == end_day) else '1-'\n",
    "    max_trip_arrival_time = end_time_prefix + end_time\n",
    "\n",
    "    duration = (end_datetime - start_datetime).seconds\n",
    "\n",
    "    # Filter out the edges that can't be used for the query\n",
    "    filtered_edges = get_filtered_edges(start_day, end_day, start_time, end_time, duration).toPandas()\n",
    "\n",
    "    def to_dt(time):\n",
    "        \"\"\"\n",
    "        Convert the time to a useful format for the implementation of the algorithm\n",
    "        \"\"\"\n",
    "\n",
    "        if time == 'null':\n",
    "            return 'null'\n",
    "        elif time >= start_time:\n",
    "            return '0-' + time\n",
    "        else:\n",
    "            return '1-' + time\n",
    "\n",
    "\n",
    "    filtered_edges['departure_time'] = filtered_edges['departure_time'].map(lambda x: to_dt(x))\n",
    "    filtered_edges['arrival_time']   = filtered_edges['arrival_time'].map(lambda x: to_dt(x))\n",
    "\n",
    "    # Create a networkx graph of all the valid edges\n",
    "    subgraph = nx.from_pandas_edgelist(filtered_edges, 'src', 'dst', edge_attr=True, create_using=nx.MultiDiGraph())\n",
    "\n",
    "    if heatmap:\n",
    "        return compute_heatmap(subgraph, departure_station, departure_station,\n",
    "                               min_trip_departure_time, max_trip_arrival_time, duration,\n",
    "                               min_probability_of_success)\n",
    "    \n",
    "    else:\n",
    "        return dfs(subgraph, departure_station, arrival_station, min_trip_departure_time, \n",
    "                   max_trip_arrival_time, duration, min_probability_of_success, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'departure time': '19:09:00',\n",
       " 'arrival_time': '19:51:00',\n",
       " 'duration': '00:42:00',\n",
       " 'probability': 0.9997405493724597,\n",
       " 'path': [{'src': 'Kilchberg',\n",
       "   'dst': 'Zrich HB',\n",
       "   'type': 'Zug',\n",
       "   'line': 'S8',\n",
       "   'departure_time': '19:09:00',\n",
       "   'arrival_time': '19:23:00'},\n",
       "  {'src': 'Zrich HB',\n",
       "   'dst': 'Glanzenberg',\n",
       "   'type': 'Zug',\n",
       "   'line': 'S3',\n",
       "   'departure_time': '19:29:00',\n",
       "   'arrival_time': '19:40:00'},\n",
       "  {'src': 'Glanzenberg',\n",
       "   'dst': 'Urdorf, Schlierenstrasse',\n",
       "   'type': 'walk',\n",
       "   'departure_time': '19:40:00',\n",
       "   'arrival_time': '19:51:00'}]}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fromStation = 'Kilchberg'\n",
    "toStation   = 'Urdorf, Schlierenstrasse'\n",
    "endDateTime   = datetime(2019, 6, 4, 19, 57)\n",
    "\n",
    "res = plan(fromStation, toStation, \n",
    "           end_datetime=endDateTime,\n",
    "           min_probability_of_success=0.95)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'departure time': '12:26:00',\n",
       " 'arrival_time': '13:06:00',\n",
       " 'duration': '00:40:00',\n",
       " 'probability': 0.9923541531625337,\n",
       " 'path': [{'src': 'Kilchberg',\n",
       "   'dst': 'Zrich HB',\n",
       "   'type': 'Zug',\n",
       "   'line': 'S24',\n",
       "   'departure_time': '12:26:00',\n",
       "   'arrival_time': '12:39:00'},\n",
       "  {'src': 'Zrich HB',\n",
       "   'dst': 'Zrich Altstetten',\n",
       "   'type': 'Zug',\n",
       "   'line': 'S19',\n",
       "   'departure_time': '12:41:00',\n",
       "   'arrival_time': '12:46:00'},\n",
       "  {'src': 'Zrich Altstetten',\n",
       "   'dst': 'Glanzenberg',\n",
       "   'type': 'Zug',\n",
       "   'line': 'S12',\n",
       "   'departure_time': '12:51:00',\n",
       "   'arrival_time': '12:55:00'},\n",
       "  {'src': 'Glanzenberg',\n",
       "   'dst': 'Urdorf, Schlierenstrasse',\n",
       "   'type': 'walk',\n",
       "   'departure_time': '12:55:00',\n",
       "   'arrival_time': '13:06:00'}]}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fromStation = 'Kilchberg'\n",
    "toStation   = 'Urdorf, Schlierenstrasse'\n",
    "startDateTime = datetime(2017, 9, 13, 12, 20)\n",
    "\n",
    "res = plan(fromStation, toStation, \n",
    "           start_datetime=startDateTime,\n",
    "           min_probability_of_success=0.95)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kilchberg': 2500.0,\n",
       " 'Zrich HB': 916.6666666666666,\n",
       " 'Zrich Hardbrcke': 333.3333333333333,\n",
       " 'Zrich Hardbrcke, Bahnhof': 250.0,\n",
       " 'Zrich Stadelhofen': 666.6666666666666,\n",
       " 'Zrich Tiefenbrunnen': 83.33333333333333,\n",
       " 'Zrich Stadelhofen FB': 583.3333333333333,\n",
       " 'Zrich Kreuzplatz': 166.66666666666666,\n",
       " 'Zrich, Bellevue': 333.3333333333333,\n",
       " 'Zrich, Opernhaus': 500.0,\n",
       " 'Zrich, Kreuzstrasse': 250.0,\n",
       " 'Zrich, Helmhaus': 83.33333333333333,\n",
       " 'Zrich, Hottingerplatz': 83.33333333333333,\n",
       " 'Zrich, Kunsthaus': 166.66666666666666,\n",
       " 'Zrich, Sprecherstrasse': 333.3333333333333,\n",
       " 'Zrich Oerlikon': 166.66666666666666,\n",
       " 'Zrich Oerlikon, Bahnhof': 83.33333333333333,\n",
       " 'Zrich Altstetten': 416.66666666666663,\n",
       " 'Zrich Altstetten, Bahnhof': 333.3333333333333,\n",
       " 'Zrich Altstetten, Bahnhof N': 250.0,\n",
       " 'Zrich, Baslerstrasse': 83.33333333333333,\n",
       " 'Zrich, Bristenstrasse': 166.66666666666666,\n",
       " 'Zrich, Wrzgraben': 83.33333333333333,\n",
       " 'Zrich HB SZU': 750.0,\n",
       " 'Zrich Landesmuseum (See)': 750.0,\n",
       " 'Zrich Storchen': 83.33333333333333,\n",
       " 'Zrich Central (Polybahn)': 500.0,\n",
       " 'Zrich Polyterrasse': 416.66666666666663,\n",
       " 'Hochschulen': 416.66666666666663,\n",
       " 'Zrich Limmatquai': 333.3333333333333,\n",
       " 'Zrich, Bahnhofplatz/HB': 750.0,\n",
       " 'Zrich, Bahnhofquai/HB': 750.0,\n",
       " 'Zrich, Central': 583.3333333333333,\n",
       " 'Zrich, Bahnhofstrasse/HB': 666.6666666666666,\n",
       " 'Zrich, Beckenhof': 250.0,\n",
       " 'Zrich, ETH/Universittsspital': 166.66666666666666,\n",
       " 'Zrich, Haldenbach': 250.0,\n",
       " 'Zrich, Haldenegg': 500.0,\n",
       " 'Zrich, Lwenplatz': 583.3333333333333,\n",
       " 'Zrich, Museum fr Gestaltung': 250.0,\n",
       " 'Zrich, Neumarkt': 83.33333333333333,\n",
       " 'Zrich, Neumhlequai/HB': 666.6666666666666,\n",
       " 'Zrich, Ottikerstrasse': 83.33333333333333,\n",
       " 'Zrich, Rathaus': 166.66666666666666,\n",
       " 'Zrich, Rennweg': 333.3333333333333,\n",
       " 'Zrich, Rudolf-Brun-Brcke': 416.66666666666663,\n",
       " 'Zrich, Sihlpost/HB': 333.3333333333333,\n",
       " 'Zrich, Sihlquai/HB': 583.3333333333333,\n",
       " 'Zrich, Sonneggstrasse': 333.3333333333333,\n",
       " 'Zrich, Stampfenbachplatz': 583.3333333333333,\n",
       " 'Zrich, Winkelriedstrasse': 83.33333333333333,\n",
       " 'Zrich Wiedikon': 1333.3333333333333,\n",
       " 'Zrich, Goldbrunnenplatz': 583.3333333333333,\n",
       " 'Zrich Selnau': 666.6666666666666,\n",
       " 'Zrich Wiedikon, Bahnhof': 1250.0,\n",
       " 'Zrich, Bckeranlage': 500.0,\n",
       " 'Zrich Selnau, Bahnhof': 666.6666666666666,\n",
       " 'Zrich, Bertastrasse': 500.0,\n",
       " 'Zrich, Bezirksgebude': 916.6666666666666,\n",
       " 'Zrich, Helvetiaplatz': 750.0,\n",
       " 'Zrich,Kalkbreite/Bhf.Wiedikon': 916.6666666666666,\n",
       " 'Zrich, Kanonengasse': 333.3333333333333,\n",
       " 'Zrich, Kernstrasse': 916.6666666666666,\n",
       " 'Zrich, Lochergut': 666.6666666666666,\n",
       " 'Zrich, Militr-/Langstrasse': 333.3333333333333,\n",
       " 'Zrich, Schmiede Wiedikon': 916.6666666666666,\n",
       " 'Zrich, Sihlstrasse': 416.66666666666663,\n",
       " 'Zrich, Stauffacher': 833.3333333333333,\n",
       " 'Zrich, Werd': 1000.0,\n",
       " 'Zrich, Zwinglihaus': 750.0,\n",
       " 'Zrich, Zypressenstrasse': 333.3333333333333,\n",
       " 'Zrich Wollishofen': 1666.6666666666665,\n",
       " 'Zimmerberg-Basistunnel': 666.6666666666666,\n",
       " 'Zrich Brunau': 833.3333333333333,\n",
       " 'Zrich Saalsporthalle': 416.66666666666663,\n",
       " 'Zrich, Saalsporthalle': 250.0,\n",
       " 'Zrich, Sihlcity': 416.66666666666663,\n",
       " 'Zrich Manegg': 166.66666666666666,\n",
       " 'Zrich Wollishofen (See)': 1333.3333333333333,\n",
       " 'Zrich, Rote Fabrik': 1083.3333333333333,\n",
       " 'Zrich, Besenrainstrasse': 1166.6666666666665,\n",
       " 'Zrich Wollishofen, Bhf (Bus)': 1583.3333333333333,\n",
       " 'Zrich Wollishofen, Bhf (Tram)': 1583.3333333333333,\n",
       " 'Zrich, Billoweg': 1166.6666666666665,\n",
       " 'Zrich, Brunau/Mutschellenstr.': 666.6666666666666,\n",
       " 'Zrich, Brunaustrasse': 666.6666666666666,\n",
       " 'Zrich, Butzenstrasse': 916.6666666666666,\n",
       " 'Zrich, Jugendherberge': 1250.0,\n",
       " 'Zrich, Kalchbhlweg': 1000.0,\n",
       " 'Zrich, Landiwiese': 1250.0,\n",
       " 'Zrich, Morgental': 1166.6666666666665,\n",
       " 'Zrich, Post Wollishofen': 1250.0,\n",
       " 'Zrich, Sukkulentensammlung': 750.0,\n",
       " 'Zrich, Thujastrasse': 1083.3333333333333,\n",
       " 'Zrich, Verenastrasse': 666.6666666666666,\n",
       " 'Zrich Enge': 1416.6666666666665,\n",
       " 'Zrich Binz': 416.66666666666663,\n",
       " 'Zrich Giesshbel': 666.6666666666666,\n",
       " 'Zrich Enge (See)': 666.6666666666666,\n",
       " 'Zrich Brkliplatz (See)': 583.3333333333333,\n",
       " 'Zrich Enge, Bahnhof': 1333.3333333333333,\n",
       " 'Zrich Enge, Bahnhof/Bederstr.': 1333.3333333333333,\n",
       " 'Zrich, Brsenstrasse': 583.3333333333333,\n",
       " 'Zrich, Brandschenkestrasse': 750.0,\n",
       " 'Zrich, Brkliplatz': 583.3333333333333,\n",
       " 'Zrich, Hgelstrasse': 666.6666666666666,\n",
       " 'Zrich, Hrlimannplatz': 1000.0,\n",
       " 'Zrich, Manesseplatz': 666.6666666666666,\n",
       " 'Zrich, Museum Rietberg': 1000.0,\n",
       " 'Zrich, Paradeplatz': 500.0,\n",
       " 'Zrich, Rentenanstalt': 1083.3333333333333,\n",
       " 'Zrich, Schweizer Rck': 750.0,\n",
       " 'Zrich, Sihlcity Nord': 666.6666666666666,\n",
       " 'Zrich, Stockerstrasse': 833.3333333333333,\n",
       " 'Zrich, Tunnelstrasse': 1083.3333333333333,\n",
       " 'Zrich, Waffenplatz-/Bederstr.': 916.6666666666666,\n",
       " 'Zrich, Waffenplatzstrasse': 916.6666666666666,\n",
       " 'Zrich, Binz': 416.66666666666663,\n",
       " 'Thalwil': 916.6666666666666,\n",
       " 'Thalwil (See)': 583.3333333333333,\n",
       " 'Thalwil, Feldstrasse': 166.66666666666666,\n",
       " 'Thalwil, Mhlebachplatz': 333.3333333333333,\n",
       " 'Thalwil, Zentrum': 750.0,\n",
       " 'Thalwil, Bahnhof': 833.3333333333333,\n",
       " 'Thalwil, Aegertli': 500.0,\n",
       " 'Thalwil, Archstrasse': 666.6666666666666,\n",
       " 'Thalwil, In Reben': 333.3333333333333,\n",
       " 'Thalwil, Pilgerweg': 500.0,\n",
       " 'Thalwil, Platte': 166.66666666666666,\n",
       " 'Thalwil, Post': 666.6666666666666,\n",
       " 'Thalwil, Rudishaldenstrasse': 333.3333333333333,\n",
       " 'Thalwil, Seehaldenstrasse': 83.33333333333333,\n",
       " 'Thalwil, Trotte': 333.3333333333333,\n",
       " 'Thalwil, Zehntenstrasse': 83.33333333333333,\n",
       " 'Thalwil, Sonnenberg': 166.66666666666666,\n",
       " 'Rschlikon': 1166.6666666666665,\n",
       " 'Rschlikon (See)': 750.0,\n",
       " 'Rschlikon, Bahnhof': 1000.0,\n",
       " 'Rschlikon, Belvoir': 666.6666666666666,\n",
       " 'Rschlikon, Bodengasse': 750.0,\n",
       " 'Rschlikon, Eggrain': 250.0,\n",
       " 'Rschlikon, Langhaldenstrasse': 833.3333333333333,\n",
       " 'Rschlikon, Loorain': 166.66666666666666,\n",
       " 'Rschlikon, Moosstrasse': 250.0,\n",
       " 'Rschlikon, Park im Grene': 250.0,\n",
       " 'Rschlikon, Rebsteig': 416.66666666666663,\n",
       " 'Rschlikon, Sumerstrasse': 416.66666666666663,\n",
       " 'Rschlikon, Schlossstrasse': 416.66666666666663,\n",
       " 'Rschlikon, Weidstrasse': 916.6666666666666,\n",
       " 'Thalwil, Park im Grene': 166.66666666666666,\n",
       " 'Zrich Wipkingen': 166.66666666666666,\n",
       " 'Zrich Wipkingen, Bahnhof': 83.33333333333333,\n",
       " 'Kilchberg ZH (See)': 2083.333333333333,\n",
       " 'Kilchberg ZH, Altersheim': 1750.0,\n",
       " 'Kilchberg ZH, Auf Brunnen': 1833.3333333333333,\n",
       " 'Kilchberg ZH, Bchlerstrasse': 1666.6666666666665,\n",
       " 'Kilchberg ZH, Bahnhof': 2416.6666666666665,\n",
       " 'Kilchberg ZH, Bendlikon': 2166.6666666666665,\n",
       " 'Kilchberg ZH, Gottlieb-Binder': 2000.0,\n",
       " 'Kilchberg ZH, Hallenbad': 1500.0,\n",
       " 'Kilchberg ZH, Hornhaldenstr.': 1500.0,\n",
       " 'Kilchberg ZH, Kirche': 1583.3333333333333,\n",
       " 'Kilchberg ZH, Spital': 1500.0,\n",
       " 'Kilchberg ZH, Kreuzstrasse': 2250.0,\n",
       " 'Kilchberg ZH, Lindt & Sprngli': 1833.3333333333333,\n",
       " 'Kilchberg ZH, Mythenstrasse': 1833.3333333333333,\n",
       " 'Kilchberg ZH, Paradiessteig': 1750.0,\n",
       " 'Kilchberg ZH, Paradiesstrasse': 2000.0,\n",
       " 'Kilchberg ZH, Sanatorium': 2083.333333333333,\n",
       " 'Kilchberg ZH, Schlimbergstr.': 2083.333333333333,\n",
       " 'Kilchberg ZH, Schooren': 1583.3333333333333,\n",
       " 'Kilchberg ZH, Schoorenstrasse': 1666.6666666666665,\n",
       " 'Kilchberg ZH,Schulhaus Dorfstr': 2166.6666666666665,\n",
       " 'Kilchberg ZH, Schwelle': 2083.333333333333,\n",
       " 'Kilchberg ZH, Stockengut': 1916.6666666666665,\n",
       " 'Kilchberg ZH, Weinbergstrasse': 1583.3333333333333,\n",
       " 'Kilchberg ZH, Breitloo': 1750.0,\n",
       " 'Kilchberg ZH, Emilienheim': 1583.3333333333333}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fromStation = 'Kilchberg'\n",
    "startDateTime = datetime(2019, 6, 4, 15, 20)\n",
    "\n",
    "res = plan(fromStation, \n",
    "           start_datetime=startDateTime,\n",
    "           min_probability_of_success=0.95, heatmap=True, heatmap_duration=30)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = spark.read.csv('/datasets/sbb/2017/*/*istdaten.csv.bz2', sep=';', header=True)\n",
    "stations = pd.read_csv('data/filtered_stations.csv')\n",
    "valid_stations = set(stations['Remark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateFormat = 'dd.MM.yyyy HH:mm'\n",
    "\n",
    "arrivals = df.filter((df.DURCHFAHRT_TF=='false') & \n",
    "                     (df.FAELLT_AUS_TF=='false') & \n",
    "                     (df.ZUSATZFAHRT_TF=='false') &\n",
    "                     (df.AN_PROGNOSE_STATUS=='GESCHAETZT') &\n",
    "                     (df.HALTESTELLEN_NAME.isin(valid_stations))) \\\n",
    "             .select('LINIEN_TEXT', \n",
    "                     'HALTESTELLEN_NAME', \n",
    "                     'ANKUNFTSZEIT', \n",
    "                     'AN_PROGNOSE') \\\n",
    "             .withColumn('AN_PROGNOSE',  functions.to_timestamp(df.AN_PROGNOSE, dateFormat))  \\\n",
    "             .withColumn('ANKUNFTSZEIT',  functions.to_timestamp(df.ANKUNFTSZEIT, dateFormat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrivals.write.parquet('/homes/schmutz/validation_stops', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_stops = spark.read.parquet('/homes/schmutz/validation_stops')\n",
    "stations = pd.read_csv('data/filtered_stations.csv')\n",
    "valid_stations = list(stations['Remark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_VALIDATION_WEEKS = 15\n",
    "\n",
    "DAYS = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "DATE = {'Monday'    : date(2017, 9, 18),\n",
    "        'Tuesday'   : date(2017, 9, 19),\n",
    "        'Wednesday' : date(2017, 9, 13),\n",
    "        'Thursday'  : date(2017, 9, 14),\n",
    "        'Friday'    : date(2017, 9, 15),\n",
    "        'Saturday'  : date(2017, 9, 16),\n",
    "        'Sunday'    : date(2017, 9, 17)}\n",
    "\n",
    "\n",
    "def get_stops(stations_set, lines_set, arrivals_set):\n",
    "\n",
    "    arrivals = val_stops.filter((val_stops.LINIEN_TEXT.isin(lines_set)) &\n",
    "                                (val_stops.ANKUNFTSZEIT.isin(arrivals_set)) &\n",
    "                                (val_stops.HALTESTELLEN_NAME.isin(stations_set))) \\\n",
    "                        .drop(val_stops.ANKUNFTSZEIT)\n",
    "    \n",
    "    \n",
    "    arr_df = arrivals.toPandas()\n",
    "    arr_df.columns = ['line', 'station', 'arrival_time']\n",
    "    \n",
    "    return arr_df\n",
    "\n",
    "\n",
    "def to_timeobj(timestr):\n",
    "    t = timestr.split(':')\n",
    "    return dt.time(int(t[0]), int(t[1]), int(t[2]))\n",
    "\n",
    "\n",
    "def is_trip_valid(trip, end_time=None):\n",
    "    for idx, edge in enumerate(trip):\n",
    "        if idx > 0:\n",
    "            if trip[idx - 1]['arrival_time'] > edge['departure_time'] or \\\n",
    "               (end_time != None and edge['arrival_time'] > end_time):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def check_query(query_res, trip_dt, mode):\n",
    "    \n",
    "    trip_dt_str = str(trip_dt.date())\n",
    "    \n",
    "    s_set = set()\n",
    "    l_set = set()\n",
    "    a_set = set()\n",
    "\n",
    "    for edge in query_res['path']:\n",
    "        if edge['type'] != 'walk':\n",
    "            s_set.add(edge['dst'])\n",
    "            l_set.add(edge['line'])\n",
    "            a_set.add(trip_dt_str + ' ' + edge['arrival_time'])\n",
    "\n",
    "    arrivals = get_stops(s_set, l_set, a_set)\n",
    "\n",
    "    new_path = []\n",
    "\n",
    "    for e in query_res['path']:\n",
    "        edge = e.copy()\n",
    "        if edge['type'] != 'walk':\n",
    "            entry = arrivals[(arrivals['line'] == edge['line']) & (arrivals['station'] == edge['dst'])]\n",
    "            \n",
    "            if len(entry.values) == 0:\n",
    "                # trip didn't happend at all that day\n",
    "                return 'pass'\n",
    "            \n",
    "            timestr = str(entry.values[0][2])[11:]\n",
    "            edge['arrival_time'] = to_timeobj(timestr)\n",
    "            edge['departure_time'] = to_timeobj(edge['departure_time'])\n",
    "        else:\n",
    "            edge['departure_time'] = to_timeobj(edge['departure_time'])\n",
    "            edge['arrival_time'] = to_timeobj(edge['arrival_time'])\n",
    "\n",
    "        new_path.append(edge)\n",
    "\n",
    "    for idx, edge in enumerate(new_path):\n",
    "        if edge['type'] == 'walk' and idx > 0:\n",
    "            prev_arr = new_path[idx - 1]['arrival_time']\n",
    "            if (prev_arr > edge['departure_time']):\n",
    "                timediff = datetime.combine(date.today(), prev_arr) - datetime.combine(date.today(), edge['departure_time'])\n",
    "                edge['departure_time'] = prev_arr\n",
    "                edge['arrival_time'] = (datetime.combine(date.today(), edge['arrival_time']) + timediff).time()\n",
    "    \n",
    "    \n",
    "    if mode == 'arrival':\n",
    "        return is_trip_valid(new_path, end_time=trip_dt.time())\n",
    "    else :\n",
    "        return is_trip_valid(new_path)\n",
    "\n",
    "\n",
    "def validate_query(departure_station, arrival_station, min_probability_of_success, \n",
    "                   start_datetime=None, end_datetime=None):\n",
    "\n",
    "    if (start_datetime == None and end_datetime == None) or \\\n",
    "       (start_datetime != None and end_datetime != None):\n",
    "        return False\n",
    "    \n",
    "    elif start_datetime != None:\n",
    "        mode = 'departure'\n",
    "        query_res = plan(departure_station, arrival_station, \n",
    "                         start_datetime=start_datetime,\n",
    "                         min_probability_of_success=0.95)\n",
    "        \n",
    "        trip_dt = start_datetime\n",
    "    \n",
    "    else:\n",
    "        mode = 'arrival'\n",
    "        query_res = plan(departure_station, arrival_station, \n",
    "                         end_datetime=end_datetime,\n",
    "                         min_probability_of_success=0.95)\n",
    "        \n",
    "        trip_dt = end_datetime\n",
    "    \n",
    "    if not query_res['path']:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    trip_dts = []\n",
    "    for i in range(NUM_VALIDATION_WEEKS):\n",
    "        trip_dts.append(trip_dt + timedelta(weeks=i))\n",
    "    \n",
    "    \n",
    "    nb_valids = 0\n",
    "    nb_invalids = 0\n",
    "    for trip_dt in trip_dts:\n",
    "        query_state = check_query(query_res, trip_dt, mode)\n",
    "        if query_state == 'pass':\n",
    "            pass\n",
    "        elif query_state:\n",
    "            nb_valids += 1\n",
    "        else:\n",
    "            nb_invalids += 1\n",
    "\n",
    "    return nb_valids + nb_invalids, nb_valids, query_res['probability']\n",
    "\n",
    "\n",
    "def get_random_query():\n",
    "    day = DATE[DAYS[np.random.randint(0, len(DAYS))]]\n",
    "    h = np.random.randint(5, 22)\n",
    "    m = np.random.randint(0, 60)\n",
    "    \n",
    "    trip_datetime = datetime.combine(day, dt.time(h, m))\n",
    "    \n",
    "    departure_station = valid_stations[np.random.randint(0, len(valid_stations))]\n",
    "    \n",
    "    arrival_station = departure_station\n",
    "    while arrival_station == departure_station:\n",
    "        arrival_station = valid_stations[np.random.randint(0, len(valid_stations))]\n",
    "    \n",
    "    return departure_station, arrival_station, trip_datetime\n",
    "\n",
    "\n",
    "def benchmark_average_time_loss(mode, min_prob_success):\n",
    "    nb_validation_queries = 50\n",
    "    sum_minutes_lost = 0\n",
    "    \n",
    "    i = 0\n",
    "    while i < nb_validation_queries:\n",
    "        src, dst, trip_dt = get_random_query()\n",
    "\n",
    "        if mode == 'departure':\n",
    "            query_res = plan(departure_station, arrival_station, \n",
    "                             start_datetime=trip_dt,\n",
    "                             min_probability_of_success=min_prob_success)\n",
    "\n",
    "            if not query_res['path']:\n",
    "                continue\n",
    "            \n",
    "            naive_res = plan(departure_station, arrival_station, \n",
    "                             start_datetime=trip_dt,\n",
    "                             min_probability_of_success=0.0)\n",
    "            \n",
    "            naive_time = to_timeobj(naive_res['arrival_time'])\n",
    "            query_time = to_timeobj(query_res['arrival_time'])\n",
    "            \n",
    "            timediff = datetime.combine(date.today(), query_time) - datetime.combine(date.today(), naive_time)\n",
    "            \n",
    "            sum_minutes_lost += timediff.total_seconds() / 60\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            if i % (nb_validation_queries // 50) == 0:\n",
    "                print('#', end='')\n",
    "            \n",
    "        else:\n",
    "            query_res = plan(departure_station, arrival_station, \n",
    "                             end_datetime=trip_dt,\n",
    "                             min_probability_of_success=min_prob_success)\n",
    "\n",
    "            if not query_res['path']:\n",
    "                continue\n",
    "            \n",
    "            naive_res = plan(departure_station, arrival_station, \n",
    "                             end_datetime=trip_dt,\n",
    "                             min_probability_of_success=0.0)\n",
    "            \n",
    "            naive_time = to_timeobj(naive_res['departure_time'])\n",
    "            query_time = to_timeobj(query_res['departure_time'])\n",
    "            \n",
    "            timediff = datetime.combine(date.today(), naive_time) - datetime.combine(date.today(), query_time)\n",
    "            \n",
    "            sum_minutes_lost += timediff.total_seconds() / 60\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            if i % (nb_validation_queries // 50) == 0:\n",
    "                print('#', end='')\n",
    "    \n",
    "    return sum_minutes_lost / nb_validation_queries\n",
    "\n",
    "\n",
    "def validate_random_query(min_prob_success):\n",
    "    \n",
    "    departure_station, arrival_station, trip_datetime = get_random_query()\n",
    "    \n",
    "    mode = np.random.choice(['departure', 'arrival'])\n",
    "    \n",
    "    if mode == 'departure':\n",
    "        return validate_query(departure_station, arrival_station, min_prob_success, start_datetime=trip_datetime)\n",
    "    else:\n",
    "        return validate_query(departure_station, arrival_station, min_prob_success, end_datetime=trip_datetime)\n",
    "\n",
    "\n",
    "def validate_model(min_prob_success, nb_validation_queries=100):\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    nb_query_success = 0\n",
    "    tot_nb_trips = 0\n",
    "    tot_nb_trips_success = 0\n",
    "    sum_query_prob = 0\n",
    "    \n",
    "    while i < nb_validation_queries:\n",
    "        nb_trips, nb_trips_success, query_prob = validate_random_query(min_prob_success)\n",
    "\n",
    "        if nb_trips > 0:\n",
    "            i += 1\n",
    "            \n",
    "            if i % (nb_validation_queries // 50) == 0:\n",
    "                print('#', end='')\n",
    "            \n",
    "            if nb_trips_success / nb_trips >= min_prob_success:\n",
    "                nb_query_success += 1\n",
    "            \n",
    "            tot_nb_trips += nb_trips\n",
    "            tot_nb_trips_success += nb_trips_success\n",
    "            sum_query_prob += query_prob\n",
    "    \n",
    "    fraction_query_success = nb_query_success / nb_validation_queries\n",
    "    tot_fraction_trip_success = tot_nb_trips_success / tot_nb_trips\n",
    "    mean_query_prob = sum_query_prob / nb_validation_queries\n",
    "    \n",
    "    return fraction_query_success, tot_fraction_trip_success, mean_query_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prob_successes = [0.0, 0.25, 0.50, 0.75, 0.90]\n",
    "nb_validation_queries = 500\n",
    "\n",
    "fraction_query_successes = []\n",
    "tot_fraction_trip_successes = []\n",
    "mean_queries_prob = []\n",
    "\n",
    "for min_prob_success in min_prob_successes:\n",
    "    print('Validating with min prob {:.2f} '.format(min_prob_success), end=' ')\n",
    "    fraction_query_success, tot_fraction_trip_success, mean_query_prob = validate_model(min_prob_success, nb_validation_queries)\n",
    "    print(' done', ' {:.3f}'.format(fraction_query_success), ' {:.3f}'.format(tot_fraction_trip_success), \n",
    "          ' {:.3f}'.format(mean_query_prob))\n",
    "    \n",
    "    fraction_query_successes.append(fraction_query_success)\n",
    "    tot_fraction_trip_successes.append(tot_fraction_trip_success)\n",
    "    mean_queries_prob.append(mean_query_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prob_successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_query_successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_fraction_trip_successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_queries_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prob_successes = [0.25, 0.50, 0.75, 0.90]\n",
    "\n",
    "departure_time_loss = []\n",
    "arrival_time_loss = []\n",
    "\n",
    "for min_prob_success in min_prob_successes:\n",
    "    print('Avg dep time lost with min prob {:.2f} '.format(min_prob_success), end=' ')\n",
    "    avg_deptime_lost = benchmark_average_time_loss(mode='arrival', min_prob_success=min_prob_success)\n",
    "    print(' done', ' {:.1f}'.format(avg_deptime_lost))\n",
    "    \n",
    "    departure_time_loss.append(avg_deptime_lost)\n",
    "    \n",
    "for min_prob_success in min_prob_successes:\n",
    "    print('Avg arr time lost with min prob {:.2f} '.format(min_prob_success), end=' ')\n",
    "    avg_arrtime_lost = benchmark_average_time_loss(mode='departure', min_prob_success=min_prob_success)\n",
    "    print(' done', ' {:.1f}'.format(avg_arrtime_lost))\n",
    "    \n",
    "    arrival_time_loss.append(avg_arrtime_lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
